{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Side note: all the cells until the `Pipelining Preprocessing Steps` are similar to the cells in `...phase_1.ipynb` file, as we've worked on preprocessing steps to be used in phase 2 when writing the code for phase 1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cells for Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iL10kckWVsh1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "runningFromColab = False\n",
        "if 'CGROUP_MEMORY_EVENTS' in os.environ and 'colab' in os.environ['CGROUP_MEMORY_EVENTS']:\n",
        "  runningFromColab = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTIJGz2iHMO2",
        "outputId": "326dfca4-9445-4816-911e-b765a922e293"
      },
      "outputs": [],
      "source": [
        "if runningFromColab:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "of0Zg47kK5c6",
        "outputId": "63bb8d76-b03d-4416-d307-7316ca5bb0fc"
      },
      "outputs": [],
      "source": [
        "if runningFromColab:\n",
        "  %cd /content/drive/MyDrive/ColabProjects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzrpiAjyLPrb",
        "outputId": "7ee9cf1d-4a35-4374-fbf3-d226e19ffc11"
      },
      "outputs": [],
      "source": [
        "if runningFromColab:\n",
        "  !git clone https://github.com/OdyAsh/nlp-image-captioning.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgJWSx0ENHfi",
        "outputId": "b932304f-617a-4fa5-b586-011925faa17b"
      },
      "outputs": [],
      "source": [
        "if runningFromColab:\n",
        "  %cd /content/drive/MyDrive/ColabProjects/nlp-image-captioning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oggUYhWqPZMX",
        "outputId": "1e4791d0-9831-47ab-a2ed-5cd18121ae74"
      },
      "outputs": [],
      "source": [
        "if runningFromColab:\n",
        "  !git pull\n",
        "  # if it DOES NOT say \"Already up to date.\", then you need to close this notebook file (i.e., the browser tab) and open it again for it to change "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLTA8a3-Q7ph",
        "outputId": "bef4bb2c-d71a-49bb-f060-0e352def13ab"
      },
      "outputs": [],
      "source": [
        "# if runningFromColab:\n",
        "#   try:\n",
        "#     import condacolab\n",
        "#     condacolab.install()\n",
        "#   except:\n",
        "#     !pip install -q condacolab\n",
        "#     import condacolab\n",
        "#     condacolab.install()\n",
        "#     # now restart the kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW1oaGvGMsvN",
        "outputId": "8722ca24-ba6c-42ca-8be3-d8c103cd3897"
      },
      "outputs": [],
      "source": [
        "# if runningFromColab:\n",
        "#   !conda env create -f environment.yml\n",
        "#   # !conda update conda -y -q\n",
        "#   # !source /usr/local/etc/profile.d/conda.sh\n",
        "#   # !conda init \n",
        "#   # !conda install -n root _license -y -q\n",
        "#   # !source activate myenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7zUUVjcRLxjd"
      },
      "outputs": [],
      "source": [
        "# if runningFromColab:\n",
        "#   import sys\n",
        "#   sys.path.insert(0, '/usr/local/bin/conda')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gjH1mCsmHKZR"
      },
      "source": [
        "# Imports & Global Functions/Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "from glob import glob\n",
        "from time import time\n",
        "import os\n",
        "import pickle\n",
        "import regex as re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import LSTM, Embedding, TimeDistributed, Dense, RepeatVector,\\\n",
        "#                          Activation, Flatten, Reshape, concatenate, Dropout, BatchNormalization\n",
        "# from tensorflow.keras.layers import Bidirectional\n",
        "# from tensorflow.keras.layers import Add # merge.add\n",
        "from tensorflow.keras.applications import inception_v3 # inception_v3.preprocess_input\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras import preprocessing # preprocessing.image, preprocessing.sequence, preprocessing.text.Tokenizer, preprocessing.sequence.pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import Input, layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.optim as optim\n",
        "# from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\ashra\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pklSave(contentToBeSaved, fullPath):\n",
        "    with open(fullPath, 'wb') as f:\n",
        "        pickle.dump(contentToBeSaved, f)\n",
        "\n",
        "def pklLoad(fullPath):\n",
        "    with open(fullPath, 'rb') as f:\n",
        "        content = pickle.load(f)\n",
        "    return content\n",
        "\n",
        "def pklForceLoad(path, dtype = 'dict'):\n",
        "    try:\n",
        "        content = pklLoad(path)\n",
        "        return content\n",
        "    except Exception as e:\n",
        "        if dtype == 'list':\n",
        "            pklSave([], path)\n",
        "            return []\n",
        "        else:\n",
        "            pklSave({}, path)\n",
        "            return {}\n",
        "\n",
        "# more about naming standards for path components here: https://stackoverflow.com/questions/2235173/what-is-the-naming-standard-for-path-components\n",
        "def joinPaths(baseDirectory, relativePath):\n",
        "    return os.path.normpath(os.path.join(baseDirectory, relativePath))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8091"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datasetImgsBasePath = 'dataset/Flicker8k_Dataset/'\n",
        "fullImgsPath = glob(datasetImgsBasePath + '*.jpg')\n",
        "fullImgsPaths = [os.path.normpath(path) for path in fullImgsPath]\n",
        "len(fullImgsPaths)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Collection\n",
        "The dataset is obtained from [here](https://forms.illinois.edu/sec/1713398)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first image's captions:\n",
            "['1000268201_693b08cb0e.jpg#0\\tA child in a pink dress is climbing up a set of '\n",
            " 'stairs in an entry way .',\n",
            " '1000268201_693b08cb0e.jpg#1\\tA girl going into a wooden building .',\n",
            " '1000268201_693b08cb0e.jpg#2\\tA little girl climbing into a wooden playhouse '\n",
            " '.',\n",
            " '1000268201_693b08cb0e.jpg#3\\tA little girl climbing the stairs to her '\n",
            " 'playhouse .',\n",
            " '1000268201_693b08cb0e.jpg#4\\tA little girl in a pink dress going into a '\n",
            " 'wooden cabin .']\n",
            "\n",
            "attention image's captions:\n",
            "['1001773457_577c3a7d70.jpg#0\\tA black dog and a spotted dog are fighting',\n",
            " '1001773457_577c3a7d70.jpg#1\\tA black dog and a tri-colored dog playing with '\n",
            " 'each other on the road .',\n",
            " '1001773457_577c3a7d70.jpg#2\\tA black dog and a white dog with brown spots '\n",
            " 'are staring at each other in the street .',\n",
            " '1001773457_577c3a7d70.jpg#3\\tTwo dogs of different breeds looking at each '\n",
            " 'other on the road .',\n",
            " '1001773457_577c3a7d70.jpg#4\\tTwo dogs on pavement moving toward each other .']\n",
            "\n",
            "and so forth...\n"
          ]
        }
      ],
      "source": [
        "# checking the 5 captions per image\n",
        "filename = \"dataset/Flicker8k_TextFiles/Flickr8k.token.txt\"\n",
        "with open(filename, 'r') as f:\n",
        "    doc = f.read()\n",
        "lines = doc.split('\\n')\n",
        "print('first image\\'s captions:')\n",
        "pprint(lines[:5])\n",
        "print('\\nattention image\\'s captions:')\n",
        "pprint(lines[5:10])\n",
        "print('\\nand so forth...')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The captions above are for these two images:\n",
        "\n",
        "<img src=\"project_media/1000268201_693b08cb0e.jpg\" width=\"100\" />\n",
        "\n",
        "<img src=\"project_media/1001773457_577c3a7d70.jpg\" width=\"150\" />"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Cleaning\n",
        "Includes:\n",
        "* `imgToCaptions` dictionary\n",
        "* `cleanCaptions()` to remove stopwords/punctuations\n",
        "* `createVocab()` to limit vocab size based on word frequency\n",
        "* `train`, `val`, and `test` `ImgToCaptions` which prepends `startseq` and appends `endseq`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['A child in a pink dress is climbing up a set of stairs in an entry way .',\n",
              " 'A girl going into a wooden building .',\n",
              " 'A little girl climbing into a wooden playhouse .',\n",
              " 'A little girl climbing the stairs to her playhouse .',\n",
              " 'A little girl in a pink dress going into a wooden cabin .']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# getting these captions in a dictionary; \n",
        "# where the key is the image's name (without .jpg) and the value is a list of 5 captions\n",
        "\n",
        "imgToCaptions = dict()\n",
        "for line in lines:\n",
        "    idAndCaption = re.split(\"\\..+\\t\", line)\n",
        "    if len(idAndCaption) < 2:\n",
        "        continue\n",
        "    imgId, caption = idAndCaption\n",
        "    if imgId not in imgToCaptions:\n",
        "        imgToCaptions[imgId] = list()\n",
        "    imgToCaptions[imgId].append(caption)\n",
        "    \n",
        "imgToCaptions['1000268201_693b08cb0e']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['child in pink dress is climbing up set of stairs in entry way',\n",
              " 'girl going into wooden building',\n",
              " 'little girl climbing into wooden playhouse',\n",
              " 'little girl climbing stairs to her playhouse',\n",
              " 'little girl in pink dress going into wooden cabin']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# removing punctuation using maketrans (i.e., translation table)\n",
        "# more about maketrans method: https://www.w3schools.com/python/ref_string_maketrans.asp#:~:text=The%20third%20parameter%20in%20the%20mapping%20table%20describes%20characters%20that%20you%20want%20to%20remove%20from%20the%20string%3A\n",
        "\n",
        "\n",
        "def cleanCaptions(imgToCaptions, levelOfStopwordsPresence=1):\n",
        "    table = str.maketrans('', '', string.punctuation) # third argument: removes any character in this list: '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
        "    for key, descList in imgToCaptions.items():\n",
        "        # when this for loop is done, all 5 captions of an image will be cleaned\n",
        "        for i in range(len(descList)):\n",
        "            desc = descList[i]\n",
        "            desc = desc.split(' ')\n",
        "            desc = [word.lower() for word in desc]\n",
        "            desc = [word.translate(table) for word in desc] # remove punctuation from each token\n",
        "            stopswordsToRemove = []\n",
        "            if levelOfStopwordsPresence == 1:\n",
        "                stopswordsToRemove = ['a', 'an', 'the']\n",
        "            elif levelOfStopwordsPresence >= 2:\n",
        "                stopswordsToRemove = set(stopwords.words('english'))\n",
        "            desc = [word for word in desc if word not in stopswordsToRemove]\n",
        "            desc = [word for word in desc if word.isalpha()] # remove tokens with numbers in them\n",
        "            descList[i] =  ' '.join(desc) # store as string\n",
        "\n",
        "# cleanCaptions(imgToCaptions, levelOfStopwordsPresence=1)\n",
        "# pklSave(imgToCaptions, 'dataset/pickles/imgToCaptionsSWKept.pickle')\n",
        "imgToCaptions = pklLoad('dataset/pickles/imgToCaptionsSWKept.pickle')\n",
        "imgToCaptions['1000268201_693b08cb0e']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "example with stopwords removed:\n",
        "<br><br>\n",
        "'little girl climbing stairs playhouse',\n",
        "\n",
        "<br>\n",
        "example with only ['a', 'an', 'the'] removed:\n",
        "<br><br>\n",
        "'little girl climbing stairs to her playhouse',\n",
        "<br><br>\n",
        "from the lack of context seen above, we've decided to keep the rest of the stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original vocabulary (i.e., unique words) size: 8366\n",
            "Vocabulary size after removing less frequent words (< 5 words): 2945\n"
          ]
        }
      ],
      "source": [
        "# creating vocab of unique words (where each word occured at least freqThreshold number of times)\n",
        "def createVocab(imgToCaptions, freqThreshold = 10):\n",
        "    vocab = set()\n",
        "    for key in imgToCaptions.keys():\n",
        "        [vocab.update(desc.split()) for desc in imgToCaptions[key]]\n",
        "    print(f'Original vocabulary (i.e., unique words) size: {len(vocab)}')\n",
        "\n",
        "    # keeping words that appear at least freqThrehold number of times\n",
        "    vocabWordFreq = {key: 0 for key in vocab}\n",
        "    for key, descs in imgToCaptions.items():\n",
        "        for desc in descs:\n",
        "            descList = desc.split(' ')\n",
        "            for word in descList:\n",
        "                if word != '':\n",
        "                    vocabWordFreq[word] += 1\n",
        "    \n",
        "    vocab = set()\n",
        "    i = 0\n",
        "    for word, freq in vocabWordFreq.items():\n",
        "        if freq >= freqThreshold:\n",
        "            i += 1\n",
        "            vocab.add(word)\n",
        "            vocabWordFreq[word] = freq\n",
        "    print(f'Vocabulary size after removing less frequent words (< {freqThreshold} words): {len(vocab)}')\n",
        "\n",
        "    vocabWordFreqRemoved = {word: freq for word, freq in vocabWordFreq.items() if word not in vocabWordFreq}\n",
        "\n",
        "    return vocab, vocabWordFreq, vocabWordFreqRemoved\n",
        "\n",
        "def createVocabTxtFiles(vocabWordFreq, vocabWordFreqRemoved, filePrefix=\"vocabFreqThreshold\"):\n",
        "    with open(f'dataset/{filePrefix}.txt', 'w') as f:\n",
        "        f.write(str(dict(sorted(vocabWordFreq.items(), key=lambda x: x[1], reverse=True))))\n",
        "    with open(f'dataset/{filePrefix}Removed.txt', 'w') as f:\n",
        "        f.write(str(dict(sorted(vocabWordFreqRemoved.items(), key=lambda x: x[1], reverse=True))))\n",
        "\n",
        "freqThreshold = 5\n",
        "vocab, vocabWordFreq, vocabWordFreqRemoved = createVocab(imgToCaptions, freqThreshold)\n",
        "createVocabTxtFiles(vocabWordFreq, vocabWordFreqRemoved, filePrefix=f\"vocabFreqThreshold{freqThreshold}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Dataset: 6000\n",
            "Validation Dataset: 1000\n",
            "Test Dataset: 1000\n"
          ]
        }
      ],
      "source": [
        "# function to get filenames of images from a text file (without the extension)\n",
        "def getImgsIdsList(txtPath):\n",
        "    with open(txtPath, 'r') as f:\n",
        "        doc = f.read()\n",
        "    ImgsIds = []\n",
        "    for line in doc.split('\\n'):\n",
        "        imgId = line.split('.')[0]\n",
        "        ImgsIds.append(imgId)\n",
        "    ImgsIds = [id for id in ImgsIds if id != '']\n",
        "    return ImgsIds\n",
        "\n",
        "trainImgsIds = getImgsIdsList('dataset/Flicker8k_TextFiles/Flickr_8k.trainImages.txt')\n",
        "valImgsIds = getImgsIdsList('dataset/Flicker8k_TextFiles/Flickr_8k.devImages.txt')\n",
        "testImgsIds = getImgsIdsList('dataset/Flicker8k_TextFiles/Flickr_8k.testImages.txt')\n",
        "print(f'Train Dataset: {len(trainImgsIds)}')\n",
        "print(f'Validation Dataset: {len(valImgsIds)}')\n",
        "print(f'Test Dataset: {len(testImgsIds)}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the code below, we use `startseq` and `endseq` for the following reasons:\n",
        "* startseq : Will indicate the start of the caption generation process\n",
        "* endseq : to stop predicting words as soon as it appears"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "images in training set: 6000\n",
            "\n",
            "images in validation set: 1000\n",
            "\n",
            "images in testing set: 1000\n",
            "\n",
            "example from training set:\n",
            "['startseq black dog is running after white dog in snow endseq',\n",
            " 'startseq black dog chasing brown dog through snow endseq',\n",
            " 'startseq two dogs chase each other across snowy ground endseq',\n",
            " 'startseq two dogs play together in snow endseq',\n",
            " 'startseq two dogs running through low lying body of water endseq']\n"
          ]
        }
      ],
      "source": [
        "trainImgToCaptions = dict()\n",
        "valImgToCaptions = dict()\n",
        "testImgToCaptions = dict()\n",
        "for imgId in trainImgsIds:\n",
        "    trainImgToCaptions[imgId] = ['startseq ' + desc + ' endseq' for desc in imgToCaptions[imgId]]\n",
        "for imgId in valImgsIds:\n",
        "    valImgToCaptions[imgId] = ['startseq ' + desc + ' endseq' for desc in imgToCaptions[imgId]]\n",
        "for imgId in testImgsIds:\n",
        "    testImgToCaptions[imgId] = ['startseq ' + desc + ' endseq' for desc in imgToCaptions[imgId]]\n",
        "print(f'images in training set: {len(trainImgToCaptions)}\\n')\n",
        "print(f'images in validation set: {len(valImgToCaptions)}\\n')\n",
        "print(f'images in testing set: {len(testImgToCaptions)}\\n')\n",
        "print('example from training set:')\n",
        "pprint(trainImgToCaptions['2513260012_03d33305cf'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preparing File Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6000, 1000, 1000)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainImgsPaths = [joinPaths(datasetImgsBasePath, imgId)+'.jpg' for imgId in trainImgToCaptions.keys()]\n",
        "valImgsPaths = [joinPaths(datasetImgsBasePath, imgId)+'.jpg' for imgId in valImgToCaptions.keys()]\n",
        "testImgsPaths = [joinPaths(datasetImgsBasePath, imgId)+'.jpg' for imgId in testImgToCaptions.keys()]\n",
        "len(trainImgsPaths), len(valImgsPaths), len(testImgsPaths)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Pre-Processing\n",
        "Includes:\n",
        "* Pre-Processing Images\n",
        "* Pre-Processing Captions"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pre-Processing Images\n",
        "Includes:\n",
        "* Loading Google's `InceptionV3` model\n",
        "* Preprocessing the image\n",
        "* Encoding the image by inputting it to `InceptionV3` to get a `2048` feature vector of the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 1000) dtype=float32 (created by layer 'predictions')>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# getting the feature vector of each image using the InceptionV3 CNN model created by Google Research\n",
        "inception_model = InceptionV3(weights='imagenet') # getting the InceptionV3 model trained on imagenet data\n",
        "inception_model.layers[-1].output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 2048) dtype=float32 (created by layer 'avg_pool')>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "modelForFeatureExtraction = Model(inception_model.input, inception_model.layers[-2].output) # removing the last layer (output softmax layer)\n",
        "modelForFeatureExtraction.layers[-1].output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# function to preprocess the input image\n",
        "def preprocess(imgPath):\n",
        "    pilImg = preprocessing.image.load_img(imgPath, target_size=(299, 299)) # Convert all the images to size 299x299 as expected by the inception v3 model\n",
        "    x = preprocessing.image.img_to_array(pilImg) # Convert PIL image to numpy array of 3-dimensions\n",
        "    x = np.expand_dims(x, axis=0) # Add one more dimension; from (299, 299, 3) to (1, 299, 299, 3)\n",
        "    x = inception_v3.preprocess_input(x) # takes in (batch_size, height, width, channels), returns same dimensions, but does some preprocessing operations, like scaling values to be from -1 to 1\n",
        "    return x\n",
        "\n",
        "# function to encode a given image (from its path) into a vector of size (2048, )\n",
        "def encode(imgPath, modelForFeatureExtraction):\n",
        "    imgPath = preprocess(imgPath) # preprocess the image\n",
        "    featureVec = modelForFeatureExtraction.predict(imgPath) # Get the encoding vector for the image\n",
        "    featureVec = np.reshape(featureVec, featureVec.shape[1]) # reshape from (1, 2048) to (2048, )\n",
        "    return featureVec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6000, 1000, 1000, (2048,))"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Call the funtion to encode all the train images (dictionary where an image id --> feature vector of length 2048)\n",
        "# This will take a while on CPU - Execute this only once (took around 13 minutes on my high-end laptop)\n",
        "def encodeImgToFeatures(imgsPaths, modelForFeatureExtraction):\n",
        "    imgToFeatures = dict()\n",
        "    for imgPath in imgsPaths:\n",
        "        imgToFeatures[imgPath[len(datasetImgsBasePath):]] = encode(imgPath, modelForFeatureExtraction)\n",
        "    return imgToFeatures\n",
        "\n",
        "# trainImgToFeatures = encodeImgToFeatures(trainImgsPaths, modelForFeatureExtraction)\n",
        "# valImgToFeatures = encodeImgToFeatures(valImgsPaths, modelForFeatureExtraction)\n",
        "# testImgToFeatures = encodeImgToFeatures(testImgsPaths, modelForFeatureExtraction)\n",
        "# pklSave(trainImgToFeatures, 'dataset/pickles/trainImgToFeatures.pickle')\n",
        "# pklSave(valImgToFeatures, 'dataset/pickles/valImgToFeatures.pickle')\n",
        "# pklSave(testImgToFeatures, 'dataset/pickles/testImgToFeatures.pickle')\n",
        "trainImgToFeatures = pklLoad('dataset/pickles/trainImgToFeatures.pickle')\n",
        "valImgToFeatures = pklLoad('dataset/pickles/valImgToFeatures.pickle')\n",
        "testImgToFeatures = pklLoad('dataset/pickles/testImgToFeatures.pickle')\n",
        "len(trainImgToFeatures), len(valImgToFeatures), len(testImgToFeatures), trainImgToFeatures['2513260012_03d33305cf.jpg'].shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pre-Processing Captions\n",
        "Includes:\n",
        "* `mapIdxAndWord()` to map indices to words and vice versa, where the words are obtained from `createVocab()`\n",
        "* `maxCaptionLength()` to get the caption with the most amount of words, to be used later to pad input sequences <br> (explained in `Preparing Model Generator` section)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original vocabulary (i.e., unique words) size: 8366\n",
            "Vocabulary size after removing less frequent words (< 5 words): 2945\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "2946"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# creating two dictionaries: word to index, and index to word\n",
        "\n",
        "def mapIdxAndWord(vocab):\n",
        "    idxToWord = {}\n",
        "    wordToIdx = {}\n",
        "    idx = 1\n",
        "    for word in vocab:\n",
        "        wordToIdx[word] = idx\n",
        "        idxToWord[idx] = word\n",
        "        idx += 1\n",
        "    return idxToWord, wordToIdx\n",
        "\n",
        "vocab, _, _ = createVocab(imgToCaptions, freqThreshold=5)\n",
        "idxToWord, wordToIdx = mapIdxAndWord(vocab)\n",
        "vocabSize = len(idxToWord) + 1 # one for appended 0's; represents \"startseq\" (explained in \"Preparing Model Generator\" section)\n",
        "vocabSize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Description Length: 32\n"
          ]
        }
      ],
      "source": [
        "# getting the length of the longest caption; as we will later need to encode each word into a fixed sized vector\n",
        "\n",
        "# convert a dictionary of clean captions to a list of captions\n",
        "def toCaptionsList(ImgToCaptions):\n",
        "\tcaptionsList = list()\n",
        "\tfor imgId in ImgToCaptions.keys():\n",
        "\t\t[captionsList.append(caption) for caption in ImgToCaptions[imgId]]\n",
        "\treturn captionsList\n",
        "\n",
        "# calculate the length of the description with the most words\n",
        "def maxCaptionLength(ImgToCaptions):\n",
        "    captions = toCaptionsList(ImgToCaptions)\n",
        "    captionsLengths = [len(caption.split()) for caption in captions]\n",
        "    return max(captionsLengths)\n",
        "\n",
        "# determine the maximum sequence length\n",
        "maxCapLen = maxCaptionLength(trainImgToCaptions)\n",
        "print(f'Description Length: {maxCapLen}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "maxCaptionLength(testImgToCaptions)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Word Embedding"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using Glove Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "# run the commented code lines below once to create word_to_glove_embedding dictionary, then load it using pklLoad()\n",
        "\n",
        "# Load Glove vectors\n",
        "glove_dir = './dataset/glove_word_embeddings/'\n",
        "# word_to_glove_embedding = {} # empty dictionary\n",
        "# with open(os.path.join(glove_dir, 'glove.6B.200d.txt'), encoding=\"utf-8\") as f:\n",
        "#     for line in f:\n",
        "#         word_and_embedding_of_word = line.split()\n",
        "#         word = word_and_embedding_of_word[0]\n",
        "#         coefs = np.asarray(word_and_embedding_of_word[1:], dtype='float32')\n",
        "#         word_to_glove_embedding[word] = coefs\n",
        "# pklSave(word_to_glove_embedding, './dataset/pickles/word_to_glove_embedding.pickle')\n",
        "\n",
        "word_to_glove_embedding = pklLoad('./dataset/pickles/word_to_glove_embedding.pickle')\n",
        "\n",
        "print('Found %s word vectors.' % len(word_to_glove_embedding))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_embedding_matrix(vocabSize, embedding_dim=200):\n",
        "    # Get embedding_dim dense vector for each word in our vocabulary\n",
        "    embedding_matrix = np.zeros((vocabSize, embedding_dim))\n",
        "\n",
        "    words_with_no_embedding = []\n",
        "    for word, i in wordToIdx.items():\n",
        "        #if i < max_words:\n",
        "        embedding_vector = word_to_glove_embedding.get(word)\n",
        "        if embedding_vector is None:\n",
        "            # Words not found in the embedding index will be all zeros\n",
        "            words_with_no_embedding.append(word)\n",
        "            continue\n",
        "        embedding_matrix[i] = embedding_vector[:embedding_dim]\n",
        "\n",
        "    return embedding_matrix, words_with_no_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of words with no embeddings: 15\n",
            "which are:\n",
            "['wakeboards', 'plushie', 'corndogs', 'somthing', 'wakeboarder', 'outstreached', 'rollerblader', 'surfboarder', 'floaties', 'bicycler', 'parasails', 'dalmation', 'waterskier', 'inground', 'windsurfs']\n",
            "embedding matrix dimensions (vocab size x embedding dimensions):\n",
            "(2946, 200)\n"
          ]
        }
      ],
      "source": [
        "# for debugging: the code above will be re-written in preprocessing_pipeline()\n",
        "\n",
        "#hyperparameter:\n",
        "embedding_dim = 200 # Note: 200 is the maximum number of dimensions specified in glove.6B.200d.txt\n",
        "\n",
        "embedding_matrix, words_with_no_embedding = get_embedding_matrix(vocabSize, embedding_dim)\n",
        "print('number of words with no embeddings:', len(words_with_no_embedding))\n",
        "print('which are:')\n",
        "print(words_with_no_embedding)\n",
        "print('embedding matrix dimensions (vocab size x embedding dimensions):')\n",
        "print(embedding_matrix.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pipelining Preprocessing Steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocessing_pipeline(freq_threshold, model_for_feature_extraction, embedding_dim=200, load_features=False): # Note: in embedding_dim, 200 is the maximum number of dimensions specified in glove.6B.200d.txt\n",
        "\n",
        "    filename = \"dataset/Flicker8k_TextFiles/Flickr8k.token.txt\"\n",
        "    with open(filename, 'r') as f:\n",
        "        doc = f.read()\n",
        "    lines = doc.split('\\n')\n",
        "\n",
        "    # getting these captions in a dictionary; \n",
        "    # where the key is the image's name (without .jpg) and the value is a list of 5 captions\n",
        "    imgToCaptions = dict()\n",
        "    for line in lines:\n",
        "        idAndCaption = re.split(\"\\..+\\t\", line)\n",
        "        if len(idAndCaption) < 2:\n",
        "            continue\n",
        "        imgId, caption = idAndCaption\n",
        "        if imgId not in imgToCaptions:\n",
        "            imgToCaptions[imgId] = list()\n",
        "        imgToCaptions[imgId].append(caption)\n",
        "\n",
        "    freqThreshold = freq_threshold\n",
        "    vocab, vocabWordFreq, vocabWordFreqRemoved = createVocab(imgToCaptions, freqThreshold)\n",
        "    # createVocabTxtFiles(vocabWordFreq, vocabWordFreqRemoved, filePrefix=f\"vocabFreqThreshold{freqThreshold}\")\n",
        "    idxToWord, wordToIdx = mapIdxAndWord(vocab)\n",
        "    vocabSize = len(idxToWord) + 1 # one for appended 0's; represents \"startseq\" (explained in \"Preparing Model Generator\" section)\n",
        "\n",
        "    trainImgsIds = getImgsIdsList('dataset/Flicker8k_TextFiles/Flickr_8k.trainImages.txt')\n",
        "    valImgsIds = getImgsIdsList('dataset/Flicker8k_TextFiles/Flickr_8k.devImages.txt')\n",
        "    testImgsIds = getImgsIdsList('dataset/Flicker8k_TextFiles/Flickr_8k.testImages.txt')\n",
        "\n",
        "    trainImgToCaptions = dict()\n",
        "    valImgToCaptions = dict()\n",
        "    testImgToCaptions = dict()\n",
        "    for imgId in trainImgsIds:\n",
        "        trainImgToCaptions[imgId] = ['startseq ' + desc + ' endseq' for desc in imgToCaptions[imgId]]\n",
        "    for imgId in valImgsIds:\n",
        "        valImgToCaptions[imgId] = ['startseq ' + desc + ' endseq' for desc in imgToCaptions[imgId]]\n",
        "    for imgId in testImgsIds:\n",
        "        testImgToCaptions[imgId] = ['startseq ' + desc + ' endseq' for desc in imgToCaptions[imgId]]\n",
        "\n",
        "    datasetImgsBasePath = 'dataset/Flicker8k_Dataset/'\n",
        "    fullImgsPath = glob(datasetImgsBasePath + '*.jpg')\n",
        "    trainImgsPaths = [joinPaths(datasetImgsBasePath, imgId)+'.jpg' for imgId in trainImgToCaptions.keys()]\n",
        "    valImgsPaths = [joinPaths(datasetImgsBasePath, imgId)+'.jpg' for imgId in valImgToCaptions.keys()]\n",
        "    testImgsPaths = [joinPaths(datasetImgsBasePath, imgId)+'.jpg' for imgId in testImgToCaptions.keys()]\n",
        "\n",
        "    if load_features:\n",
        "        trainImgToFeatures = pklLoad('dataset/pickles/trainImgToFeatures.pickle')\n",
        "        valImgToFeatures = pklLoad('dataset/pickles/valImgToFeatures.pickle')\n",
        "        testImgToFeatures = pklLoad('dataset/pickles/testImgToFeatures.pickle')   \n",
        "    else: \n",
        "        trainImgToFeatures = encodeImgToFeatures(trainImgsPaths, model_for_feature_extraction) # shape of each encoded image: (2048,); returned by Google's Inception Model\n",
        "        valImgToFeatures = encodeImgToFeatures(valImgsPaths, model_for_feature_extraction)\n",
        "        testImgToFeatures = encodeImgToFeatures(testImgsPaths, model_for_feature_extraction)\n",
        "        # pklSave(trainImgToFeatures, 'dataset/pickles/trainImgToFeatures.pickle')\n",
        "    # pklSave(valImgToFeatures, 'dataset/pickles/valImgToFeatures.pickle')\n",
        "    # pklSave(testImgToFeatures, 'dataset/pickles/testImgToFeatures.pickle')\n",
        "\n",
        "    # determine the maximum sequence length\n",
        "    maxCapLen = maxCaptionLength(trainImgToCaptions)\n",
        "\n",
        "    embedding_matrix, words_with_no_embedding = get_embedding_matrix(vocabSize, embedding_dim)\n",
        "    print('number of words with no embeddings:', len(words_with_no_embedding))\n",
        "    print('which are:')\n",
        "    print(words_with_no_embedding)\n",
        "    print('embedding matrix dimensions (vocab size x embedding dimensions):')\n",
        "    print(embedding_matrix.shape)\n",
        "\n",
        "    return (imgToCaptions, vocab, vocabWordFreq, vocabWordFreqRemoved, \n",
        "            idxToWord, wordToIdx, vocabSize, maxCapLen,\n",
        "            embedding_matrix, words_with_no_embedding,\n",
        "            trainImgsIds, valImgsIds, testImgsIds, \n",
        "            trainImgToFeatures, valImgToFeatures, testImgToFeatures, \n",
        "            trainImgToCaptions, valImgToCaptions, testImgToCaptions)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.layers import LSTM, Embedding, TimeDistributed, Dense, RepeatVector,\\\n",
        "                         Activation, Flatten, Reshape, concatenate, Dropout, BatchNormalization\n",
        "import tensorflow as tf\n",
        "\n",
        "def create_lstm_model(embedding_matrix, vocabSize, droput_rate = 0.5, dense_layer_units = 256, hidden_layers_activation = 'relu'): \n",
        "    inputs1 = Input(shape=(2048,)) # 2048 is fixed, as this is an image's feature vector size returned by Google's Inception model\n",
        "    fe1 = Dropout(droput_rate)(inputs1)\n",
        "    fe2 = Dense(dense_layer_units, activation=hidden_layers_activation)(fe1)\n",
        "    inputs2 = Input(shape=(maxCapLen,))\n",
        "    se1 = Embedding(vocabSize, embedding_dim, mask_zero=True)(inputs2)\n",
        "    se2 = Dropout(droput_rate)(se1)\n",
        "    se3 = LSTM(dense_layer_units)(se2) \n",
        "    merge_img_and_txt_features = concatenate([fe2, se3])\n",
        "    decoder = Dense(dense_layer_units, activation=hidden_layers_activation)(merge_img_and_txt_features)\n",
        "    outputs = Dense(vocabSize, activation='softmax')(decoder)\n",
        "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "    \n",
        "    # setting the Embedding layer to not be trainable, as the glove embeddings fetched from the txt file are already pre-trained results\n",
        "    model.layers[2].set_weights([embedding_matrix])\n",
        "    model.layers[2].trainable = False\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['acc']) \n",
        "\n",
        "    return model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# gru Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.layers import GRU, Embedding, TimeDistributed, Dense, RepeatVector,\\\n",
        "                         Activation, Flatten, Reshape, concatenate, Dropout, BatchNormalization\n",
        "import tensorflow as tf\n",
        "\n",
        "def create_gru_model(embedding_matrix, vocabSize, droput_rate = 0.5, dense_layer_units = 256, hidden_layers_activation = 'relu'): \n",
        "    inputs1 = Input(shape=(2048,)) # 2048 is fixed, as this is an image's feature vector size returned by Google's Inception model\n",
        "    fe1 = Dropout(droput_rate)(inputs1)\n",
        "    fe2 = Dense(dense_layer_units, activation=hidden_layers_activation)(fe1)\n",
        "    inputs2 = Input(shape=(maxCapLen,))\n",
        "    se1 = Embedding(vocabSize, embedding_dim, mask_zero=True)(inputs2)\n",
        "    se2 = Dropout(droput_rate)(se1)\n",
        "    se3 = GRU(dense_layer_units)(se2)\n",
        "    merge_img_and_txt_features = concatenate([fe2, se3])\n",
        "    decoder = Dense(dense_layer_units, activation=hidden_layers_activation)(merge_img_and_txt_features)\n",
        "    outputs = Dense(vocabSize, activation='softmax')(decoder)\n",
        "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "    \n",
        "    # setting the Embedding layer to not be trainable, as the glove embeddings fetched from the txt file are already pre-trained results\n",
        "    model.layers[2].set_weights([embedding_matrix])\n",
        "    model.layers[2].trainable = False\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['acc']) \n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# failed attempt to create attention model\n",
        "\n",
        "# from keras.layers import LSTM, Embedding, Dropout, concatenate, Bidirectional\n",
        "                         \n",
        "# from keras_self_attention import SeqSelfAttention\n",
        "\n",
        "# def create_attention_model(embedding_matrix, vocabSize, droput_rate = 0.5, dense_layer_units = 256, hidden_layers_activation = 'relu'): \n",
        "#     inputs1 = Input(shape=(2048,)) # 2048 is fixed, as this is an image's feature vector size returned by Google's Inception model\n",
        "#     fe1 = Dropout(droput_rate)(inputs1)\n",
        "#     fe2 = Dense(dense_layer_units, activation=hidden_layers_activation)(fe1)\n",
        "#     inputs2 = Input(shape=(maxCapLen,))\n",
        "#     se1 = Embedding(vocabSize, embedding_dim, mask_zero=True)(inputs2)\n",
        "#     se2 = Dropout(droput_rate)(se1)\n",
        "#     se3 = LSTM(dense_layer_units, return_sequences=True)(se2) \n",
        "#     se4 = SeqSelfAttention(attention_activation='sigmoid')(se3)\n",
        "#     se5 = Flatten()(se4)\n",
        "#     print(se5)\n",
        "#     merge_img_and_txt_features = concatenate([fe2, se5])\n",
        "#     print(merge_img_and_txt_features)\n",
        "#     decoder = Dense(dense_layer_units, activation=hidden_layers_activation)(merge_img_and_txt_features)\n",
        "#     outputs = Dense(vocabSize, activation='softmax')(decoder)\n",
        "#     model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "\n",
        "#     # setting the Embedding layer to not be trainable, as the glove embeddings fetched from the txt file are already pre-trained results\n",
        "#     model.layers[1].set_weights([embedding_matrix])\n",
        "#     model.layers[1].trainable = False\n",
        "\n",
        "#     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['acc']) \n",
        "\n",
        "\n",
        "#     return model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The attempted attention model shown above failed with this code error:\n",
        "\n",
        "<img src='./project_media/failed_attention_model.png' width='800' />"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preparing Model Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data generator, intended to be used in a call to model.fit_generator()\n",
        "def dataGenerator(imgToCaptions, imgToFeatures, wordToIdx, vocabSize, maxCaptionLength, imgsBatchSize):\n",
        "    X1, X2, y = list(), list(), list()\n",
        "    n = 0\n",
        "    # loop forever over images\n",
        "    while True:\n",
        "        for imgId, captions in imgToCaptions.items():\n",
        "            n += 1\n",
        "            imgFeatures = imgToFeatures[imgId+'.jpg'] # retrieve the image's feature vector\n",
        "            for caption in captions:\n",
        "                seq = [wordToIdx[word] for word in caption.split(' ') if word in wordToIdx] # encode the caption into a sequence of numbers instead of words\n",
        "                for i in range(1, len(seq)): # split one sequence into multiple X, y pairs\n",
        "                    inSeq, outSeq = seq[:i], seq[i] # split into input and output pair\n",
        "                    inSeq = preprocessing.sequence.pad_sequences([inSeq], maxlen=maxCaptionLength, padding=\"pre\")[0] # pad input sequence\n",
        "                    outSeq = to_categorical([outSeq], num_classes=vocabSize)[0] # (one-hot) encodes the output sequence (note: to_categorical() is a keras-related function)\n",
        "                    X1.append(imgFeatures) # store the values\n",
        "                    X2.append(inSeq)\n",
        "                    y.append(outSeq)\n",
        "            # yield the batch data\n",
        "            if n == imgsBatchSize:\n",
        "                yield [[np.array(X1), np.array(X2)], np.array(y)] # \"yield\" saves the function's state, returns [[..]], then continues function from that statement when function is called again\n",
        "                X1, X2, y = list(), list(), list()\n",
        "                n = 0"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Explanation of inner-most for loop above:\n",
        "\n",
        "<img src=\"project_media/xi_as_words.png\" width=\"600\" />\n",
        "\n",
        "However, since we're using `wordToIdx` mapping, the table above will be:\n",
        "\n",
        "<img src=\"project_media/xi_as_idxss.png\" width=\"600\" />\n",
        "\n",
        "Note 1: the table above is for the case of `post` padding. However, we'll assume `pre` padding, as it is [generally advised](https://stackoverflow.com/questions/46298793/how-does-choosing-between-pre-and-post-zero-padding-of-sequences-impact-results#:~:text=I%20always%20recommend%20using%20pre%2Dpadding%20over%20post%2Dpadding%2C%20even%20for%20CNNs%2C%20unless%20the%20problem%20specifically%20requires%20post%2Dpadding.)\n",
        "\n",
        "Note 2: under the hood, `target word` is one-hot encoded representation of the numerical values displayed in the table above; this is because one-hot encoding the target word allows us to represent this probability distribution as a vector of probabilities over the entire vocabulary, which can be directly compared to the predicted probability distribution output by the neural network  \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Training"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original vocabulary (i.e., unique words) size: 9630\n",
            "Vocabulary size after removing less frequent words (< 5 words): 3107\n",
            "number of words with no embeddings: 15\n",
            "which are:\n",
            "['wakeboards', 'plushie', 'corndogs', 'somthing', 'wakeboarder', 'outstreached', 'rollerblader', 'surfboarder', 'floaties', 'bicycler', 'parasails', 'dalmation', 'waterskier', 'inground', 'windsurfs']\n",
            "embedding matrix dimensions (vocab size x embedding dimensions):\n",
            "(3108, 200)\n"
          ]
        }
      ],
      "source": [
        "# hyperparameters:\n",
        "freq_threshold = 5\n",
        "inception_model = InceptionV3(weights='imagenet') # getting the InceptionV3 model trained on imagenet data\n",
        "model_for_feature_extraction = Model(inception_model.input, inception_model.layers[-2].output) # removing the last layer (output softmax layer)\n",
        "imgs_batch_size = 32\n",
        "epochs = 30\n",
        "embedding_dim = 200\n",
        "\n",
        "(imgToCaptions, vocab, vocabWordFreq, vocabWordFreqRemoved, \n",
        "idxToWord, wordToIdx, vocabSize, maxCapLen,\n",
        "embedding_matrix, words_with_no_embedding,\n",
        "trainImgsIds, valImgsIds, testImgsIds, \n",
        "trainImgToFeatures, valImgToFeatures, testImgToFeatures, \n",
        "trainImgToCaptions, valImgToCaptions, testImgToCaptions) = preprocessing_pipeline(freq_threshold, model_for_feature_extraction, embedding_dim=embedding_dim, load_features=True) # set load_features=True if you won't change \"weights\" argument of \"model\" variable to avoid bottleneck of using Google's Inception Model\n",
        "\n",
        "lstm_wordToIdx = wordToIdx.copy()\n",
        "\n",
        "train_datagen = dataGenerator(trainImgToCaptions, trainImgToFeatures, wordToIdx, vocabSize, maxCapLen, imgs_batch_size)\n",
        "val_datagen = dataGenerator(valImgToCaptions, valImgToFeatures, wordToIdx, vocabSize, maxCapLen, imgs_batch_size)\n",
        "test_datagen = dataGenerator(testImgToCaptions, testImgToFeatures, wordToIdx, vocabSize, maxCapLen, imgs_batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model hyperparameters:\n",
        "droput_rate = 0.5\n",
        "dense_layer_units = 256\n",
        "hidden_layers_activation = 'relu'\n",
        "\n",
        "lstm_model = create_lstm_model(embedding_matrix, vocabSize, droput_rate, dense_layer_units, hidden_layers_activation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "187/187 - 61s - loss: 4.8994 - acc: 0.1876 - val_loss: 4.1860 - val_acc: 0.2496 - 61s/epoch - 328ms/step\n",
            "Epoch 2/30\n",
            "187/187 - 60s - loss: 3.9206 - acc: 0.2655 - val_loss: 3.7244 - val_acc: 0.2909 - 60s/epoch - 321ms/step\n",
            "Epoch 3/30\n",
            "187/187 - 62s - loss: 3.5576 - acc: 0.2964 - val_loss: 3.5321 - val_acc: 0.3122 - 62s/epoch - 329ms/step\n",
            "Epoch 4/30\n",
            "187/187 - 63s - loss: 3.3503 - acc: 0.3159 - val_loss: 3.4288 - val_acc: 0.3259 - 63s/epoch - 336ms/step\n",
            "Epoch 5/30\n",
            "187/187 - 64s - loss: 3.2070 - acc: 0.3287 - val_loss: 3.3809 - val_acc: 0.3339 - 64s/epoch - 342ms/step\n",
            "Epoch 6/30\n",
            "187/187 - 64s - loss: 3.0987 - acc: 0.3385 - val_loss: 3.3434 - val_acc: 0.3405 - 64s/epoch - 342ms/step\n",
            "Epoch 7/30\n",
            "187/187 - 65s - loss: 3.0080 - acc: 0.3458 - val_loss: 3.3200 - val_acc: 0.3433 - 65s/epoch - 347ms/step\n",
            "Epoch 8/30\n",
            "187/187 - 64s - loss: 2.9317 - acc: 0.3545 - val_loss: 3.3054 - val_acc: 0.3466 - 64s/epoch - 343ms/step\n",
            "Epoch 9/30\n",
            "187/187 - 64s - loss: 2.8615 - acc: 0.3616 - val_loss: 3.3202 - val_acc: 0.3463 - 64s/epoch - 344ms/step\n",
            "Epoch 10/30\n",
            "187/187 - 65s - loss: 2.8007 - acc: 0.3671 - val_loss: 3.3259 - val_acc: 0.3485 - 65s/epoch - 345ms/step\n",
            "Epoch 11/30\n",
            "187/187 - 65s - loss: 2.7487 - acc: 0.3734 - val_loss: 3.3550 - val_acc: 0.3472 - 65s/epoch - 346ms/step\n",
            "Epoch 12/30\n",
            "187/187 - 65s - loss: 2.7023 - acc: 0.3784 - val_loss: 3.3585 - val_acc: 0.3459 - 65s/epoch - 346ms/step\n",
            "Epoch 13/30\n",
            "187/187 - 65s - loss: 2.6619 - acc: 0.3832 - val_loss: 3.3648 - val_acc: 0.3448 - 65s/epoch - 345ms/step\n",
            "Epoch 14/30\n",
            "187/187 - 65s - loss: 2.6192 - acc: 0.3873 - val_loss: 3.3732 - val_acc: 0.3474 - 65s/epoch - 347ms/step\n",
            "Epoch 15/30\n",
            "187/187 - 65s - loss: 2.5815 - acc: 0.3919 - val_loss: 3.3603 - val_acc: 0.3487 - 65s/epoch - 347ms/step\n",
            "Epoch 16/30\n",
            "187/187 - 66s - loss: 2.5463 - acc: 0.3960 - val_loss: 3.4028 - val_acc: 0.3501 - 66s/epoch - 351ms/step\n",
            "Epoch 17/30\n",
            "187/187 - 67s - loss: 2.5117 - acc: 0.4002 - val_loss: 3.4334 - val_acc: 0.3488 - 67s/epoch - 356ms/step\n",
            "Epoch 18/30\n",
            "187/187 - 67s - loss: 2.4812 - acc: 0.4053 - val_loss: 3.4672 - val_acc: 0.3480 - 67s/epoch - 360ms/step\n",
            "Epoch 19/30\n",
            "187/187 - 65s - loss: 2.4579 - acc: 0.4086 - val_loss: 3.4818 - val_acc: 0.3465 - 65s/epoch - 349ms/step\n",
            "Epoch 20/30\n",
            "187/187 - 66s - loss: 2.4296 - acc: 0.4118 - val_loss: 3.5116 - val_acc: 0.3467 - 66s/epoch - 354ms/step\n",
            "Epoch 21/30\n",
            "187/187 - 67s - loss: 2.4062 - acc: 0.4146 - val_loss: 3.5476 - val_acc: 0.3493 - 67s/epoch - 356ms/step\n",
            "Epoch 22/30\n",
            "187/187 - 68s - loss: 2.3831 - acc: 0.4173 - val_loss: 3.5716 - val_acc: 0.3490 - 68s/epoch - 362ms/step\n",
            "Epoch 23/30\n",
            "187/187 - 66s - loss: 2.3571 - acc: 0.4210 - val_loss: 3.5495 - val_acc: 0.3507 - 66s/epoch - 353ms/step\n",
            "Epoch 24/30\n",
            "187/187 - 68s - loss: 2.3355 - acc: 0.4241 - val_loss: 3.5373 - val_acc: 0.3502 - 68s/epoch - 361ms/step\n",
            "Epoch 25/30\n",
            "187/187 - 67s - loss: 2.3184 - acc: 0.4260 - val_loss: 3.5654 - val_acc: 0.3525 - 67s/epoch - 361ms/step\n",
            "Epoch 26/30\n",
            "187/187 - 67s - loss: 2.2994 - acc: 0.4285 - val_loss: 3.5962 - val_acc: 0.3499 - 67s/epoch - 359ms/step\n",
            "Epoch 27/30\n",
            "187/187 - 68s - loss: 2.2826 - acc: 0.4314 - val_loss: 3.6441 - val_acc: 0.3495 - 68s/epoch - 363ms/step\n",
            "Epoch 28/30\n",
            "187/187 - 68s - loss: 2.2691 - acc: 0.4332 - val_loss: 3.7077 - val_acc: 0.3494 - 68s/epoch - 362ms/step\n",
            "Epoch 29/30\n",
            "187/187 - 68s - loss: 2.2486 - acc: 0.4372 - val_loss: 3.7232 - val_acc: 0.3481 - 68s/epoch - 363ms/step\n",
            "Epoch 30/30\n",
            "187/187 - 66s - loss: 2.2358 - acc: 0.4392 - val_loss: 3.7172 - val_acc: 0.3506 - 66s/epoch - 355ms/step\n"
          ]
        }
      ],
      "source": [
        "# hyperparameters:\n",
        "steps = len(trainImgToCaptions) // imgs_batch_size\n",
        "vsteps = len(valImgToCaptions) // imgs_batch_size\n",
        "\n",
        "tensorboardCallback = tf.keras.callbacks.TensorBoard(log_dir='models/lstm_logs', histogram_freq=1)\n",
        "# earlyStoppingCallback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "checkpointCallback = tf.keras.callbacks.ModelCheckpoint('./models/lstm_weights/lstm_epochs_of-{epoch:04d}-and_val_loss_of-{val_loss:.4f}.h5', \n",
        "                                                        verbose=0, save_weights_only=True, save_freq='epoch')\n",
        "\n",
        "train_datagen = dataGenerator(trainImgToCaptions, trainImgToFeatures, wordToIdx, vocabSize, maxCapLen, imgs_batch_size)\n",
        "lstm_history = lstm_model.fit(train_datagen, epochs=epochs, steps_per_epoch=steps, verbose=2, \n",
        "                              callbacks=[tensorboardCallback, checkpointCallback], #, earlyStoppingCallback\n",
        "                              validation_data=val_datagen, validation_steps=vsteps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "pklSave(lstm_history.history, './models/lstm_history.pickle')\n",
        "lstm_history = pklLoad('./models/lstm_history.pickle')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# after training the model, you can comment the lines above, and load the model using:\n",
        "lstm_model.load_weights(f'models/lstm_weights/lstm_model_with_{epochs}_epochs.h5')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## gru Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original vocabulary (i.e., unique words) size: 9630\n",
            "Vocabulary size after removing less frequent words (< 5 words): 3107\n",
            "number of words with no embeddings: 200\n",
            "which are:\n",
            "['Asian', 'Old', 'Girls', 'Cyclists', 'In', 'Men', 'RV', 'Easter', 'Boys', 'Person', 'Child', 'wakeboards', 'Domino', 'Adults', 'University', 'Football', 'People', 'Legos', 'plushie', 'Blond', 'An', 'Blue', 'Four', 'Closeup', 'Black', 'Yellow', 'Lady', 'Kid', 'Tan', 'Marx', 'BMX', 'Rollerblades', 'Where', 'Baseball', 'Sheltie', 'Speedo', 'Blonde', 'Crowd', 'Seven', 'corndogs', 'Brown', 'ATM', 'Frisbee', 'A', 'Distant', 'Dogs', 'mid-jump', 'European', 'somthing', 'Three', 'Children', 'Doberman', 'Snow', 'Two', 'Seattle', 'Jeep', 'Snowboarder', 'Santa', 'Bikers', 'DJ', 'Teen', 'Man', 'Biker', 'Dalmation', 'Dark', 'Light', 'Dog', 'Jack', 'Someone', 'Washington', 'The', 'Skiers', 'Number', 'Japanese', 'Hockey', 'Hawaiian', 'Female', 'New', 'Indian', 'Boy', 'Big', 'Jesus', 'Racing', 'wakeboarder', 'Group', 'Little', 'ATV', 'Girl', 'outstreached', 'Green', 'Basketball', 'Christmas', 'Kids', 'Eight', 'SUV', 'Tennis', 'rollerblader', 'Six', 'Terrier', 'This', 'hi-viz', 'There', 'Family', 'Many', 'surfboarder', 'Teenagers', 'Sooners', 'Rugby', 'hula-hoops', 'York', 'Mountain', 'Baby', 'Halloween', 'Spiderman', 'Collie', 'Florida', 'African', 'Couple', 'Obama', 'One', 'floaties', 'Chinese', 'Skateboarder', 'bicycler', 'Spectators', 'Young', 'Several', 'Woman', 'Greyhound', 'American', 'Labrador', 'Armenian', 'Grey', 'These', 'Irish', 'Claus', 'tri-colored', 'Orange', 'Miami', 'Shirtless', 'Bike', 'During', 'With', 'Skier', 'I', 'Dirt', 'parasails', 'Naked', 'Pizza', 'Jockeys', 'Mexican', 'Shephard', 'Skiiers', 'Older', 'Small', 'Jackson', 'Guy', 'Race', 'Batman', 'Smiling', 'Cyclist', 'Beautiful', 'Hiker', 'Some', 'On', 'St', 'Mohawk', 'Muzzled', 'Greyhounds', 'Oklahoma', 'Five', 'Eastern', 'Surfer', 'Red', 'Spider-Man', 'Mouse', 'Wet', 'At', 'Toddler', 'White', 'They', 'TV', 'Shepherd', 'Water', 'German', 'waterskier', 'Soccer', 'inground', 'Golden', 'T-shirt', 'Large', 'Women', 'Michael', 'Free', 'windsurfs', 'While', 'Street', 'Mickey', 'Middle', 'Boston']\n",
            "embedding matrix dimensions (vocab size x embedding dimensions):\n",
            "(3108, 200)\n"
          ]
        }
      ],
      "source": [
        "# hyperparameters to tune\n",
        "freq_threshold = 5\n",
        "inception_model = InceptionV3(weights='imagenet') # getting the InceptionV3 model trained on imagenet data\n",
        "model_for_feature_extraction = Model(inception_model.input, inception_model.layers[-2].output) # removing the last layer (output softmax layer)\n",
        "imgs_batch_size = 32\n",
        "epochs = 30\n",
        "embedding_dim = 200\n",
        "\n",
        "(imgToCaptions, vocab, vocabWordFreq, vocabWordFreqRemoved, \n",
        "idxToWord, wordToIdx, vocabSize, maxCapLen,\n",
        "embedding_matrix, words_with_no_embedding,\n",
        "trainImgsIds, valImgsIds, testImgsIds, \n",
        "trainImgToFeatures, valImgToFeatures, testImgToFeatures, \n",
        "trainImgToCaptions, valImgToCaptions, testImgToCaptions) = preprocessing_pipeline(freq_threshold, model_for_feature_extraction, embedding_dim=embedding_dim, load_features=True) # set load_features=True if you won't change \"weights\" argument of \"model\" variable to avoid bottleneck of using Google's Inception Model\n",
        "\n",
        "gru_wordToIdx = wordToIdx.copy()\n",
        "\n",
        "train_datagen = dataGenerator(trainImgToCaptions, trainImgToFeatures, wordToIdx, vocabSize, maxCapLen, imgs_batch_size)\n",
        "val_datagen = dataGenerator(valImgToCaptions, valImgToFeatures, wordToIdx, vocabSize, maxCapLen, imgs_batch_size)\n",
        "test_datagen = dataGenerator(testImgToCaptions, testImgToFeatures, wordToIdx, vocabSize, maxCapLen, imgs_batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model hyperparameters:\n",
        "droput_rate = 0.5\n",
        "dense_layer_units = 256\n",
        "hidden_layers_activation = 'relu'\n",
        "\n",
        "gru_model = create_gru_model(embedding_matrix, vocabSize, droput_rate, dense_layer_units, hidden_layers_activation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "187/187 - 63s - loss: 3.7445 - acc: 0.2834 - val_loss: 3.5765 - val_acc: 0.3090 - 63s/epoch - 339ms/step\n",
            "Epoch 2/30\n",
            "187/187 - 64s - loss: 3.4199 - acc: 0.3110 - val_loss: 3.3979 - val_acc: 0.3268 - 64s/epoch - 342ms/step\n",
            "Epoch 3/30\n",
            "187/187 - 64s - loss: 3.2328 - acc: 0.3277 - val_loss: 3.3075 - val_acc: 0.3376 - 64s/epoch - 343ms/step\n",
            "Epoch 4/30\n",
            "187/187 - 66s - loss: 3.0973 - acc: 0.3395 - val_loss: 3.2582 - val_acc: 0.3457 - 66s/epoch - 351ms/step\n",
            "Epoch 5/30\n",
            "187/187 - 67s - loss: 2.9942 - acc: 0.3488 - val_loss: 3.2268 - val_acc: 0.3521 - 67s/epoch - 360ms/step\n",
            "Epoch 6/30\n",
            "187/187 - 68s - loss: 2.9113 - acc: 0.3561 - val_loss: 3.2119 - val_acc: 0.3542 - 68s/epoch - 363ms/step\n",
            "Epoch 7/30\n",
            "187/187 - 67s - loss: 2.8357 - acc: 0.3633 - val_loss: 3.2288 - val_acc: 0.3527 - 67s/epoch - 360ms/step\n",
            "Epoch 8/30\n",
            "187/187 - 68s - loss: 2.7715 - acc: 0.3689 - val_loss: 3.2426 - val_acc: 0.3521 - 68s/epoch - 362ms/step\n",
            "Epoch 9/30\n",
            "187/187 - 67s - loss: 2.7123 - acc: 0.3744 - val_loss: 3.2563 - val_acc: 0.3533 - 67s/epoch - 356ms/step\n",
            "Epoch 10/30\n",
            "187/187 - 68s - loss: 2.6632 - acc: 0.3819 - val_loss: 3.2766 - val_acc: 0.3546 - 68s/epoch - 362ms/step\n",
            "Epoch 11/30\n",
            "187/187 - 70s - loss: 2.6174 - acc: 0.3864 - val_loss: 3.2984 - val_acc: 0.3540 - 70s/epoch - 374ms/step\n",
            "Epoch 12/30\n",
            "187/187 - 69s - loss: 2.5782 - acc: 0.3914 - val_loss: 3.2921 - val_acc: 0.3566 - 69s/epoch - 369ms/step\n",
            "Epoch 13/30\n",
            "187/187 - 76s - loss: 2.5398 - acc: 0.3957 - val_loss: 3.3221 - val_acc: 0.3513 - 76s/epoch - 406ms/step\n",
            "Epoch 14/30\n",
            "187/187 - 72s - loss: 2.5071 - acc: 0.3997 - val_loss: 3.3434 - val_acc: 0.3512 - 72s/epoch - 384ms/step\n",
            "Epoch 15/30\n",
            "187/187 - 71s - loss: 2.4779 - acc: 0.4029 - val_loss: 3.3380 - val_acc: 0.3535 - 71s/epoch - 381ms/step\n",
            "Epoch 16/30\n",
            "187/187 - 121s - loss: 2.4545 - acc: 0.4064 - val_loss: 3.3812 - val_acc: 0.3530 - 121s/epoch - 645ms/step\n",
            "Epoch 17/30\n",
            "187/187 - 121s - loss: 2.4246 - acc: 0.4101 - val_loss: 3.4054 - val_acc: 0.3559 - 121s/epoch - 647ms/step\n",
            "Epoch 18/30\n",
            "187/187 - 119s - loss: 2.4000 - acc: 0.4131 - val_loss: 3.4005 - val_acc: 0.3550 - 119s/epoch - 634ms/step\n",
            "Epoch 19/30\n",
            "187/187 - 120s - loss: 2.3766 - acc: 0.4160 - val_loss: 3.4214 - val_acc: 0.3552 - 120s/epoch - 644ms/step\n",
            "Epoch 20/30\n",
            "187/187 - 122s - loss: 2.3546 - acc: 0.4194 - val_loss: 3.4719 - val_acc: 0.3540 - 122s/epoch - 654ms/step\n",
            "Epoch 21/30\n",
            "187/187 - 118s - loss: 2.3310 - acc: 0.4225 - val_loss: 3.4848 - val_acc: 0.3541 - 118s/epoch - 632ms/step\n",
            "Epoch 22/30\n",
            "187/187 - 119s - loss: 2.3108 - acc: 0.4260 - val_loss: 3.4902 - val_acc: 0.3539 - 119s/epoch - 636ms/step\n",
            "Epoch 23/30\n",
            "187/187 - 119s - loss: 2.2956 - acc: 0.4279 - val_loss: 3.5118 - val_acc: 0.3545 - 119s/epoch - 637ms/step\n",
            "Epoch 24/30\n",
            "187/187 - 120s - loss: 2.2756 - acc: 0.4307 - val_loss: 3.5167 - val_acc: 0.3545 - 120s/epoch - 642ms/step\n",
            "Epoch 25/30\n",
            "187/187 - 120s - loss: 2.2615 - acc: 0.4329 - val_loss: 3.5137 - val_acc: 0.3580 - 120s/epoch - 639ms/step\n",
            "Epoch 26/30\n",
            "187/187 - 119s - loss: 2.2401 - acc: 0.4371 - val_loss: 3.5412 - val_acc: 0.3562 - 119s/epoch - 637ms/step\n",
            "Epoch 27/30\n",
            "187/187 - 118s - loss: 2.2277 - acc: 0.4385 - val_loss: 3.5585 - val_acc: 0.3567 - 118s/epoch - 633ms/step\n",
            "Epoch 28/30\n",
            "187/187 - 118s - loss: 2.2129 - acc: 0.4400 - val_loss: 3.5890 - val_acc: 0.3548 - 118s/epoch - 631ms/step\n",
            "Epoch 29/30\n",
            "187/187 - 120s - loss: 2.1994 - acc: 0.4418 - val_loss: 3.5886 - val_acc: 0.3565 - 120s/epoch - 639ms/step\n",
            "Epoch 30/30\n",
            "187/187 - 118s - loss: 2.1858 - acc: 0.4439 - val_loss: 3.5945 - val_acc: 0.3551 - 118s/epoch - 632ms/step\n"
          ]
        }
      ],
      "source": [
        "# hyperparameters:\n",
        "steps = len(trainImgToCaptions) // imgs_batch_size\n",
        "vsteps = len(valImgToCaptions) // imgs_batch_size\n",
        "\n",
        "tensorboardCallback = tf.keras.callbacks.TensorBoard(log_dir='models/gru_logs', histogram_freq=1)\n",
        "# earlyStoppingCallback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "checkpointCallback = tf.keras.callbacks.ModelCheckpoint('./models/gru_weights/gru_epochs_of-{epoch:04d}-and_val_loss_of-{val_loss:.4f}.h5', \n",
        "                                                        verbose=0, save_weights_only=True, save_freq='epoch')\n",
        "\n",
        "train_datagen = dataGenerator(trainImgToCaptions, trainImgToFeatures, wordToIdx, vocabSize, maxCapLen, imgs_batch_size)\n",
        "gru_history = gru_model.fit(train_datagen, epochs=epochs, steps_per_epoch=steps, verbose=2, \n",
        "                                        callbacks=[tensorboardCallback, checkpointCallback], # , earlyStoppingCallback\n",
        "                                        validation_data=val_datagen, validation_steps=vsteps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "pklSave(gru_history.history, './models/gru_history.pickle')\n",
        "gru_history = pklLoad('./models/gru_history.pickle')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# after training the model, you can comment the lines above, and load the model using:\n",
        "gru_model.load_weights(f'models/gru_weights/gru_model_with_{epochs}_epochs.h5')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Image Inference Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "def greedy_search(model, img_features, max_cap_len, word_to_idx, idx_to_word):\n",
        "    in_text = 'startseq'\n",
        "    # we reshape to (1,2048) instead of (2048,) as #rows must indicate the #samples\n",
        "    img_features = img_features.reshape(1, 2048) \n",
        "    for i in range(maxCapLen):\n",
        "        sequence = [word_to_idx[w] for w in in_text.split() if w in word_to_idx]\n",
        "        # this returns shape (1, max_cap_len)\n",
        "        sequence = preprocessing.sequence.pad_sequences([sequence], maxlen=max_cap_len) \n",
        "        yhat = model.predict([img_features, sequence], verbose=0)\n",
        "        yhat = np.argmax(yhat)\n",
        "        word = idx_to_word[yhat]\n",
        "        in_text += ' ' + word\n",
        "        if word == 'endseq':\n",
        "            break\n",
        "    final = in_text.split()\n",
        "    final_caption_list = final[1:-1]\n",
        "    final_caption_string = ' '.join(final)\n",
        "    return final_caption_list, final_caption_string"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Rogue & Bleu Metrics Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow_text as text\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "def calculate_metrics(metric_type, model, test_img_paths, test_img_to_features, test_img_to_captions, max_cap_len, word_to_idx):\n",
        "    idx_to_word = {v: k for k, v in lstm_wordToIdx.items()}\n",
        "    rogue_scores = []\n",
        "    bleu_scores = []\n",
        "    predicted_captions = []\n",
        "    for img_path in test_img_paths:\n",
        "        # basename() gets filename (id and .jpg), splitext() gives us tuple of (id, extension), so we write [0] to get id only\n",
        "        img_id = os.path.splitext(os.path.basename(img_path))[0] \n",
        "        img_captions_including_startend_seqs = test_img_to_captions[img_id]\n",
        "        img_features = test_img_to_features[img_id+'.jpg']\n",
        "\n",
        "        img_captions = []\n",
        "        for caption in img_captions_including_startend_seqs:\n",
        "            img_captions.append(caption[1:-1]) # removing 'startseq' and 'endseq' from the 5 captions of an image\n",
        "\n",
        "        prediction_as_list, prediction_as_string = greedy_search(model, img_features, max_cap_len, word_to_idx, idx_to_word)\n",
        "\n",
        "        if metric_type == 'rogue' or \"all\":\n",
        "            # rogue-l documentation: https://www.tensorflow.org/text/api_docs/python/text/metrics/rouge_l\n",
        "            # the metric measures how similar two sequences are, based on the length of the longest common subsequence (LCS)\n",
        "            # therefore, we take the max similarity between the hypothesis (y_pred) and one of the 5 captions of an image (y_true) \n",
        "            y_pred = tf.ragged.constant([prediction_as_list])\n",
        "            print(y_pred)\n",
        "            max_f1 = 0\n",
        "            for y_true in img_captions:\n",
        "                y_true = y_true.split(' ')\n",
        "                y_true = tf.ragged.constant([y_true])\n",
        "                # 0.5 means both precision and recall are given the same weight. more details here: https://www.tensorflow.org/text/tutorials/text_similarity#:~:text=ROUGE%2DL%20has%20an%20additional%20hyperparameter%2C%20alpha%2C%20which%20determines%20the%20weight%20of%20the%20harmonic%20mean%20used%20for%20computing%20the%20F%2DMeasure.%20Values%20closer%20to%200%20treat%20Recall%20as%20more%20important%20and%20values%20closer%20to%201%20treat%20Precision%20as%20more%20important \n",
        "                f1, precision, recall = text.metrics.rouge_l(y_pred, y_true, alpha=0.5)\n",
        "                # converting a tensor object (i.e., Tensor([x])) to just a float (i.e., x)\n",
        "                f1 = float(f1[0])\n",
        "                if f1 > max_f1:\n",
        "                    max_f1 = f1     \n",
        "            rogue_scores.append(max_f1)\n",
        "        if metric_type == 'bleu' or 'all':\n",
        "            # sentence_bleu tutorial: https://www.digitalocean.com/community/tutorials/bleu-score-in-python\n",
        "            y_pred = prediction_as_list\n",
        "            y_true_all_img_captions = []\n",
        "            for caption in img_captions:\n",
        "                y_true_all_img_captions.append(caption.split(' '))\n",
        "\n",
        "            bleu_score = sentence_bleu(y_true_all_img_captions, y_pred)\n",
        "            rogue_scores.append(bleu_score)\n",
        "\n",
        "        predicted_captions.append(prediction_as_string)\n",
        "\n",
        "    if metric_type == 'all':\n",
        "        return rogue_scores, bleu_scores, predicted_captions\n",
        "    elif metric_type == 'rogue':\n",
        "        return rogue_scores, bleu_scores, predicted_captions\n",
        "    elif metric_type == 'bleu':\n",
        "        return bleu_scores, predicted_captions\n",
        "    else:\n",
        "        return predicted_captions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test Set Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "images_dir = './dataset/Flicker8k_Dataset/'\n",
        "test_imgs_encoded = pklLoad('./dataset/pickles/testImgToFeatures.pickle')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LSTM Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# hyperparameters used when model was trained:\n",
        "droput_rate = 0.5\n",
        "dense_layer_units = 256\n",
        "hidden_layers_activation = 'relu'\n",
        "\n",
        "current_lstm_model = create_lstm_model(embedding_matrix, vocabSize, droput_rate, dense_layer_units, hidden_layers_activation)\n",
        "current_lstm_model.load_weights(f'models/lstm_weights/lstm_epochs_of-0030-and_val_loss_of-3.7172.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<tf.RaggedTensor [[b'brown', b'dog', b'is', b'running', b'on', b'the', b'grass', b'.',\n",
            "  b'of', b'a', b'body', b'of', b'water', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\CS\\projects\\nlp-image-captioning\\.conda\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "d:\\CS\\projects\\nlp-image-captioning\\.conda\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<tf.RaggedTensor [[b'water', b'squirts', b'with', b'a', b'red', b'and', b'white', b'life',\n",
            "  b'jacket', b'.', b'out', b'of', b'the', b'water', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'pool', b'.', b'.',\n",
            "  b'pool', b'.', b'.', b'pool', b'.', b'.', b'pool', b'.', b'.', b'.',\n",
            "  b'.']]>\n",
            "<tf.RaggedTensor [[b'older', b'man', b'in', b'a', b'red', b'shirt', b'and', b'red',\n",
            "  b'shorts', b'is', b'walking', b'on', b'a', b'sidewalk', b'with', b'a',\n",
            "  b'colorful', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'people', b'are', b'sitting', b'at', b'a', b'table', b'in', b'front',\n",
            "  b'of', b'a', b'building', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'in', b'Sooners', b'uniform', b'Sooners', b'Sooners', b'Sooners',\n",
            "  b'Sooners', b'Sooners', b'football', b'Sooners', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.']]>\n",
            "<tf.RaggedTensor [[b'yellow', b'dog', b'running', b'through', b'the', b'grass', b'.', b'.',\n",
            "  b'.', b'in', b'the', b'background', b'.', b'.', b'in', b'the',\n",
            "  b'background', b'.', b'.', b'in', b'the', b'background', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'wave', b'in', b'a', b'crowd', b'.', b'a', b'crowd', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'brown', b'dog', b'is', b'licking', b'a', b'white', b'dog', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'by', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'black', b'dog', b'with', b'red', b'collar', b'running', b'in', b'the',\n",
            "  b'snow', b'.', b'with', b'red', b'collar', b'.', b'in', b'the',\n",
            "  b'background', b'.', b'.', b'in', b'the', b'.', b'.', b'.', b'in',\n",
            "  b'the', b'.', b'.', b'in', b'the', b'.', b'.', b'with', b'red',\n",
            "  b'collar', b'.', b'in', b'the', b'.']]>\n",
            "<tf.RaggedTensor [[b'basketball', b'player', b'in', b'white', b'uniform', b'attempting',\n",
            "  b'to', b'score', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'shot', b'.', b'.', b'.', b'on', b'court']]>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\CS\\projects\\nlp-image-captioning\\.conda\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<tf.RaggedTensor [[b'people', b'are', b'walking', b'along', b'a', b'sidewalk', b'.', b'by',\n",
            "  b'a', b'fence', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'man', b'with', b'a', b'nose', b'piercing', b'and', b'beard', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'dogs', b'are', b'playing', b'in', b'a', b'grassy', b'area', b'.',\n",
            "  b'.', b'of', b'a', b'tree', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'from', b'the', b'ground', b'.', b'from', b'the', b'ground', b'.']]>\n",
            "<tf.RaggedTensor [[b'older', b'man', b'in', b'a', b'red', b'shirt', b'and', b'jeans',\n",
            "  b'stands', b'outside', b'of', b'a', b'building', b'.', b'.', b'a',\n",
            "  b'book', b'.', b'.', b'.', b'on', b'it', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'man', b'in', b'camouflage', b'clothing', b'stands', b'on', b'cement',\n",
            "  b'ledge', b'with', b'a', b'mountain', b'.', b'behind', b'him', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'driver', b'.', b'.', b'.', b'driver', b'.', b'.', b'driver', b'.',\n",
            "  b'.', b'driver', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'people', b'are', b'standing', b'in', b'front', b'of', b'a', b'red',\n",
            "  b'building', b'.', b'a', b'crowd', b'of', b'people', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'brown', b'dog', b'is', b'jumping', b'over', b'a', b'red', b'Frisbee',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'young', b'boy', b'wearing', b'a', b'blue', b'shirt', b'and', b'blue',\n",
            "  b'jeans', b'sits', b'on', b'a', b'wooden', b'bench', b'.', b'a',\n",
            "  b'carnival', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'brown', b'dog', b'jumping', b'into', b'a', b'puddle', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'woman', b'sitting', b'on', b'a', b'chair', b'.', b'with', b'a',\n",
            "  b'camera', b'.', b'.', b'his', b'right', b'.', b'and', b'a', b'book',\n",
            "  b'.', b'on', b'the', b'floor', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'climber', b'walking', b'across', b'a', b'snowy', b'mountain', b'.',\n",
            "  b'.', b'.', b'out', b'of', b'frame', b'.', b'.', b'.', b'on', b'the',\n",
            "  b'horizon', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'young', b'boy', b'sitting', b'on', b'a', b'bench', b'with', b'a',\n",
            "  b'small', b'boy', b'in', b'the', b'background', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'people', b'are', b'standing', b'around', b'a', b'street', b'.', b'of',\n",
            "  b'a', b'native', b'of', b'people', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'sled', b'in', b'red', b'jacket', b'doing', b'a', b'jump', b'on', b'a',\n",
            "  b'sled', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'submerged', b'way', b'driving', b'way', b'through', b'a', b'muddy',\n",
            "  b'trail', b'of', b'water', b'.', b'road', b'.', b'way', b'.', b'.',\n",
            "  b'way', b'.', b'way', b'.', b'way', b'.', b'way', b'.', b'way', b'.',\n",
            "  b'way', b'.', b'way', b'.', b'way', b'.', b'way', b'.', b'way', b'.',\n",
            "  b'way', b'.', b'way']]>\n",
            "<tf.RaggedTensor [[b'people', b'walking', b'down', b'the', b'street', b'.', b'One', b'a',\n",
            "  b'busy', b'street', b'.', b'of', b'a', b'store', b'.', b'.', b'.',\n",
            "  b'One', b'a', b'store', b'.', b'.', b'.', b'One', b'the', b'street',\n",
            "  b'.', b'One', b'a', b'store', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'woman', b'in', b'black', b'and', b'white', b'cap', b'with', b'no',\n",
            "  b'shirt', b'sits', b'in', b'front', b'of', b'a', b'brick', b'wall',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"',\n",
            "  b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"']]>\n",
            "<tf.RaggedTensor [[b'elderly', b'woman', b'wearing', b'a', b'blue', b'shirt', b'and',\n",
            "  b'tie', b'hat', b'is', b'staring', b'at', b'a', b'woman', b\"'s\",\n",
            "  b'head', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.']]>\n",
            "<tf.RaggedTensor [[b'rock', b'climber', b'scaling', b'a', b'rock', b'face', b'.', b'from',\n",
            "  b'the', b'ground', b'.', b'.', b'from', b'the', b'top', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'man', b'in', b'black', b'jacket', b'and', b'black', b'jacket',\n",
            "  b'sitting', b'on', b'a', b'cellphone', b'.', b'.', b'a', b'book', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'are', b'in', b'a', b'red', b'and', b'white', b'uniform', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'in',\n",
            "  b'the', b'uniforms', b'.', b'.', b'behind', b'him']]>\n",
            "<tf.RaggedTensor [[b'rock', b'climber', b'scaling', b'a', b'rock', b'face', b'.', b'from',\n",
            "  b'a', b'rock', b'face', b'.', b'.', b'from', b'the', b'top', b'.', b'.',\n",
            "  b'.', b'.', b'climb', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'climb', b'.', b'.', b'.', b'.', b'.', b'climb', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'attack', b'dogs', b'play', b'in', b'a', b'large', b'area', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'from', b'the', b'floor', b'.', b'of', b'a',\n",
            "  b'heavily', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'by', b'it', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'people', b'are', b'sitting', b'on', b'a', b'boat', b'in', b'the',\n",
            "  b'middle', b'of', b'a', b'body', b'of', b'water', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'brown', b'dog', b'is', b'walking', b'through', b'the', b'grass', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'in', b'the', b'area', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'sunset', b'with', b'fishing', b'head', b'and', b'a', b'fishing',\n",
            "  b'pole', b'jacket', b'.', b'on', b'the', b'beach', b'.', b'of', b'a',\n",
            "  b'lake', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'girl', b'in', b'green', b'shirt', b'and', b'blue', b'shorts',\n",
            "  b'jumping', b'on', b'sand', b'beach', b'.', b'in', b'green', b'grass',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'on',\n",
            "  b'the']]>\n",
            "<tf.RaggedTensor [[b'dog', b'jumps', b'over', b'a', b'white', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'Miami', b'basketball', b'players', b'are', b'playing', b'basketball',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'on', b'the', b'court', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'on', b'court', b'.', b'.', b'.', b'.', b'on', b'court']]>\n",
            "<tf.RaggedTensor [[b'people', b'walking', b'down', b'a', b'street', b'.', b'talking',\n",
            "  b'to', b'a', b'building', b'.', b'.', b'.', b'.', b'on', b'the',\n",
            "  b'left', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'no', b'baby', b'with', b'no', b'shirt', b'reaching', b'his',\n",
            "  b'shoulders', b'reaching', b'a', b'balance', b'.', b'.', b'.',\n",
            "  b'balance', b'balance', b'.', b'.', b'balance', b'balance', b'.',\n",
            "  b'her', b'hand', b'.', b'.', b'.', b'balance', b'.', b'.', b'balance',\n",
            "  b'balance', b'.', b'.', b'balance', b'balance', b'.', b'.', b'balance',\n",
            "  b'balance']]>\n",
            "<tf.RaggedTensor [[b'people', b'walking', b'down', b'a', b'sidewalk', b'with', b'a',\n",
            "  b'lot', b'of', b'people', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'and', b'a', b'man', b'sit', b'on', b'a', b'subway', b'train', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b\"'s\", b\"'s\", b\"'s\", b\"'s\", b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b\"'s\", b\"'s\"]]>\n",
            "<tf.RaggedTensor [[b'man', b'in', b'red', b'shirt', b'scaling', b'on', b'rock', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'climb', b'.', b'.', b'balance', b'.']]>\n",
            "<tf.RaggedTensor [[b'people', b'are', b'standing', b'on', b'a', b'rock', b'overlooking',\n",
            "  b'the', b'grassy', b'area', b'.', b'to', b'the', b'left', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'little', b'boy', b'in', b'a', b'blue', b'outfit', b'is', b'kneeling',\n",
            "  b'a', b'piece', b'of', b'red', b'and', b'white', b'floor', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'boy', b'in', b'red', b'shirt', b'jumping', b'off', b'of', b'a',\n",
            "  b'blue', b'wall', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'on', b'wall', b'.', b'.', b'wall', b'.', b'wall']]>\n",
            "<tf.RaggedTensor [[b'skiers', b'in', b'red', b'jacket', b'and', b'helmet', b'skiing',\n",
            "  b'downhill', b'.', b'on', b'snow', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'on', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'dogs', b'are', b'playing', b'in', b'a', b'grassy', b'field', b'.',\n",
            "  b'.', b'a', b'second', b'.', b'.', b'.', b'from', b'it', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'two', b'young', b'men', b'walking', b'on', b'a', b'beach', b'with',\n",
            "  b'a', b'white', b'.', b'on', b'the', b'beach', b'.', b'the', b'the',\n",
            "  b'right', b'.', b'.', b'on', b'the', b'beach', b'.', b'.', b'on',\n",
            "  b'the', b'water', b'.', b'.', b'.', b'on', b'the', b'beach', b'.', b'.',\n",
            "  b'.', b'on', b'the']]>\n",
            "<tf.RaggedTensor [[b'bed', b'in', b'red', b'and', b'white', b'striped', b'shirt', b'and',\n",
            "  b'black', b'pants', b'sitting', b'on', b'bed', b'bed', b'bed', b'.',\n",
            "  b'on', b'bed', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'basketball', b'player', b'in', b'white', b'uniform', b'trying', b'to',\n",
            "  b'block', b'the', b'ball', b'.', b'basket', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'watch', b'.', b'.', b'watch', b'.', b'.',\n",
            "  b'watch', b'.', b'.', b'watch', b'.', b'.', b'watch', b'.', b'.',\n",
            "  b'watch', b'.', b'.', b'watch']]>\n",
            "<tf.RaggedTensor [[b'young', b'girl', b'in', b'a', b'blue', b'dress', b'is', b'holding',\n",
            "  b'a', b'red', b'and', b'white', b'checkered', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'people', b'are', b'standing', b'in', b'front', b'of', b'a',\n",
            "  b'restaurant', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'jump', b'in', b'jeans', b'and', b'black', b'pants', b'jump', b'jump',\n",
            "  b'.', b'.', b'building', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'watch', b'.', b'.', b'.', b'watch', b'.',\n",
            "  b'.', b'.', b'watch', b'.', b'.', b'the', b'jump', b'.', b'other',\n",
            "  b'people']]>\n",
            "<tf.RaggedTensor [[b'white', b'dog', b'is', b'splashing', b'in', b'the', b'water', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'swing', b'sitting', b'on', b'swing', b'swing', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'rock', b'climber', b'wearing', b'a', b'blue', b'shirt', b'standing',\n",
            "  b'on', b'a', b'rock', b'overlooking', b'the', b'rocks', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'black', b'dogs', b'are', b'playing', b'in', b'the', b'water', b'.',\n",
            "  b'.', b'the', b'water', b'.', b'.', b'it', b'.', b'their', b'mouths',\n",
            "  b'.', b'.', b'the', b'water', b'.', b'.', b'it', b'.', b'off', b'the',\n",
            "  b'water', b'.', b'off', b'it', b'.', b'.', b'the', b'water', b'.',\n",
            "  b'off', b'it', b'.']]>\n",
            "<tf.RaggedTensor [[b'young', b'boy', b'wearing', b'a', b'helmet', b'and', b'a', b'white',\n",
            "  b'shirt', b'is', b'walking', b'on', b'a', b'city', b'street', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'fisherman', b'in', b'a', b'lake', b'.', b'looking', b'at', b'the',\n",
            "  b'camera', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'shot', b'.',\n",
            "  b'.', b'on', b'the', b'lake', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'boy', b'boy', b'on', b'a', b'bench', b'.', b'on', b'a', b'wooden',\n",
            "  b'bench', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'on', b'a', b'motorcycle', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'on', b'road', b'.',\n",
            "  b'.', b'.', b'.', b'on', b'road', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'on', b'road', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'basketball', b'player', b'in', b'white', b'uniform', b'holding', b'a',\n",
            "  b'basketball', b'.', b'while', b'another', b'man', b'watches', b'.',\n",
            "  b'on', b'the', b'back', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'cyclist', b'riding', b'on', b'a', b'bike', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'heavily', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'ready', b'to', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'women', b'in', b'black', b'and', b'white', b'.', b'singing', b'.',\n",
            "  b'.', b'.', b'.', b'\"', b'.', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"',\n",
            "  b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"',\n",
            "  b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"']]>\n",
            "<tf.RaggedTensor [[b'are', b'in', b'action', b'and', b'one', b'person', b'in', b'the',\n",
            "  b'water', b'.', b'on', b'the', b'water', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'on', b'the',\n",
            "  b'water', b'.', b'.', b'in', b'background', b'.', b'.', b'.', b'.',\n",
            "  b'.']]>\n",
            "<tf.RaggedTensor [[b'white', b'white', b'dog', b'with', b'white', b'open', b'and',\n",
            "  b'white', b'dog', b'on', b'sand', b'beach', b'.', b'on', b'the',\n",
            "  b'ground', b'.', b'on', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'on', b'the', b'ground', b'.', b'.', b'on', b'the',\n",
            "  b'ground', b'.', b'on', b'the']]>\n",
            "<tf.RaggedTensor [[b'man', b'sitting', b'on', b'a', b'bench', b'with', b'a', b'trashcan',\n",
            "  b'.', b'on', b'it', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'dog', b'jumps', b'over', b'a', b'white', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'on', b'the', b'ground', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b\"'s\", b'dog', b'jumps']]>\n",
            "<tf.RaggedTensor [[b'people', b'walking', b'through', b'a', b'field', b'.', b'.', b'a',\n",
            "  b'rocky', b'shore', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'dogs', b'are', b'playing', b'with', b'a', b'red', b'Frisbee', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'looks', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'skirts', b'in', b'white', b'foreground', b'.', b'with', b'other',\n",
            "  b'people', b'in', b'the', b'background', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'examine', b'.', b'.', b'.', b'.', b'examine', b'.', b'.', b'.',\n",
            "  b'examine']]>\n",
            "<tf.RaggedTensor [[b'two', b'people', b'are', b'standing', b'on', b'a', b'dock',\n",
            "  b'looking', b'at', b'the', b'water', b'.', b'.', b'over', b'the',\n",
            "  b'water', b'.', b'.', b'over', b'the', b'water', b'.', b'.', b'over',\n",
            "  b'the', b'water', b'.', b'from', b'the', b'water', b'.', b'over',\n",
            "  b'the', b'water', b'.', b'from', b'the', b'water', b'.']]>\n",
            "<tf.RaggedTensor [[b'park', b'jumping', b'off', b'a', b'set', b'of', b'stairs', b'.', b'.',\n",
            "  b'.', b'.', b'reach', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'reach', b'.', b'.', b'.', b'reach', b'.', b'.',\n",
            "  b'.', b'reach', b'.', b'.', b'.', b'reach', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'trick', b'bike', b'rider', b'jumping', b'off', b'a', b'ramp', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'on', b'a', b'ramp', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'watch', b'.', b'.', b'on', b'a', b'ramp']]>\n",
            "<tf.RaggedTensor [[b'smiling', b'woman', b'with', b'a', b'blue', b'shirt', b'is',\n",
            "  b'blowing', b'a', b'white', b'camera', b'.', b'her', b'eyes', b'closed',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'skier', b'in', b'red', b'jacket', b'jumping', b'over', b'a', b'snowy',\n",
            "  b'hill', b'.', b'.', b'on', b'a', b'snowy', b'hill', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'boy', b'boy', b'with', b'a', b'white', b'and', b'white', b'shirt',\n",
            "  b'on', b'the', b'beach', b'.', b'the', b'the', b'left', b'.', b'.',\n",
            "  b'.', b'on', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'children', b'are', b'playing', b'soccer', b'on', b'a', b'sidewalk',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b\"'s\", b\"'s\", b\"'s\", b\"'s\"]]>\n",
            "<tf.RaggedTensor [[b'rock', b'climber', b'climbing', b'a', b'rock', b'face', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'photograph', b'.', b'.', b'.', b'photograph', b'.', b'.',\n",
            "  b'photograph']]>\n",
            "<tf.RaggedTensor [[b'man', b'in', b'a', b'red', b'hat', b'and', b'blue', b'jeans', b'is',\n",
            "  b'walking', b'on', b'a', b'beach', b'.', b'.', b'a', b'beach', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'dirt', b'bike', b'riders', b'on', b'a', b'dirt', b'track', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'in', b'the', b'forest', b'.', b'in', b'the',\n",
            "  b'forest', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'rock', b'climber', b'scaling', b'a', b'rock', b'face', b'.', b'.',\n",
            "  b'covered', b'rock', b'face', b'.', b'\"', b'.', b'\"', b'.', b'\"', b'.',\n",
            "  b'\"', b'.', b'\"', b'\"', b'.', b'\"', b'\"', b'.', b'\"', b'\"', b'.', b'\"',\n",
            "  b'\"', b'.', b'\"', b'\"', b'.', b'\"', b'\"', b'.', b'\"']]>\n",
            "<tf.RaggedTensor [[b'jump', b'in', b'midair', b'attempting', b'to', b'jump', b'into', b'a',\n",
            "  b'net', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'legs', b'girl', b'in', b'black', b'and', b'white', b'shirt', b'doing',\n",
            "  b'a', b'trick', b'on', b'a', b'skateboard', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'white', b'dog', b'is', b'running', b'through', b'the', b'water', b'.',\n",
            "  b'.', b'.', b'in', b'background', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'in', b'the', b'water', b'.',\n",
            "  b'alongside', b'.', b'.', b'.', b'.', b'in', b'background', b'.', b'.',\n",
            "  b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'boy', b'boy', b'on', b'a', b'bench', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'watch', b'.', b'.', b'.', b'.',\n",
            "  b'watch', b'.', b'.', b'.', b'.', b'.', b'watch']]>\n",
            "<tf.RaggedTensor [[b'dogs', b'are', b'running', b'through', b'a', b'grassy', b'field',\n",
            "  b'.', b'a', b'large', b'brown', b'dog', b'smelling', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'during', b'a', b'game', b'.', b'a', b'heavily', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'driver',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'by', b'people',\n",
            "  b'watch', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'woman', b'in', b'a', b'blue', b'shirt', b'and', b'jeans', b'sits',\n",
            "  b'on', b'a', b'horse', b'with', b'a', b'young', b'boy', b'covering',\n",
            "  b'a', b'red', b'covering', b'covering', b'her', b'face', b'.', b'her',\n",
            "  b'mouth', b'.', b'.', b'her', b'mouth', b'.', b'.', b'her', b'mouth',\n",
            "  b'.', b'.', b'her', b'mouth', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'dogs', b'play', b'in', b'snow', b'.', b'.', b'the', b'ground', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b\"'s\", b'mouths', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b\"'s\", b'dog', b'looks', b'in', b'the',\n",
            "  b'snow', b'.', b'from', b'the', b'dog', b'.', b'in', b'the', b'snow']]>\n",
            "<tf.RaggedTensor [[b'wet', b'dog', b'running', b'on', b'beach', b'.', b'with', b'a',\n",
            "  b'tennis', b'ball', b'in', b'its', b'mouth', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'girls', b'in', b'bathing', b'suits', b'are', b'playing', b'in', b'a',\n",
            "  b'shallow', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'in', b'the', b'skirts']]>\n",
            "<tf.RaggedTensor [[b'basketball', b'player', b'in', b'white', b'uniform', b'with', b'a',\n",
            "  b'basketball', b'in', b'a', b'white', b'uniform', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'ready', b'to',\n",
            "  b'block', b'.']]>\n",
            "<tf.RaggedTensor [[b'jump', b'in', b'white', b'shirt', b'and', b'black', b'pants',\n",
            "  b'jumping', b'on', b'a', b'street', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'soccer', b'ball', b'in', b'a', b'field', b'.', b'a', b'blue', b'ball',\n",
            "  b'.', b'the', b'the', b'ground', b'.', b'on', b'the', b'ground', b'.',\n",
            "  b'.', b'outstreached', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'cold', b'in', b'uniform', b'walk', b'on', b'the', b'street', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'on', b'the', b'street', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'on']]>\n",
            "<tf.RaggedTensor [[b'african', b'american', b'african', b'a', b'paddle', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'by', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'by']]>\n",
            "<tf.RaggedTensor [[b'brown', b'dog', b'is', b'jumping', b'over', b'a', b'large', b'white',\n",
            "  b'.', b'.', b'out', b'of', b'frame', b'.', b'.', b'.', b'out', b'of',\n",
            "  b'frame', b'.', b'.', b'.', b'.', b'out', b'of', b'frame', b'.', b'.',\n",
            "  b'.', b'.', b'out', b'of', b'frame', b'.', b'.', b'.', b'.', b'out',\n",
            "  b'of']]>\n",
            "<tf.RaggedTensor [[b'dogs', b'are', b'playing', b'in', b'a', b'field', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'behind', b'it', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'people', b'are', b'standing', b'on', b'a', b'rock', b'.', b'with',\n",
            "  b'a', b'rope', b'.', b'in', b'the', b'background', b'.', b'the', b'the',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'players', b'are', b'playing', b'soccer', b'.', b'the', b'the',\n",
            "  b'ball', b'.', b'the', b'catch', b'the', b'ball', b'.', b'the',\n",
            "  b'other', b'team', b'.', b'the', b'the', b'team', b'.', b'from', b'the',\n",
            "  b'team', b'team', b'member', b'for', b'the', b'ball', b'.', b'from',\n",
            "  b'the', b'team', b'team', b'member', b'for', b'the', b'ball']]>\n",
            "<tf.RaggedTensor [[b'people', b'are', b'gathered', b'in', b'a', b'crowded', b'area', b'.',\n",
            "  b'.', b'of', b'a', b'crowd', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'black', b'dogs', b'play', b'in', b'the', b'snow', b'.', b'a', b'lake',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'into', b'the',\n",
            "  b'snow', b'.', b'.', b'shot', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'dog', b'running', b'through', b'a', b'wooded', b'area', b'.', b'from',\n",
            "  b'the', b'ground', b'.', b'from', b'the', b'ground', b'.', b'from',\n",
            "  b'the', b'ground', b'.', b'from', b'the', b'ground', b'.', b'from',\n",
            "  b'the', b'ground', b'.', b'from', b'the', b'ground', b'.', b'from',\n",
            "  b'the', b'ground', b'.', b'from', b'the', b'ground', b'.']]>\n",
            "<tf.RaggedTensor [[b'man', b'in', b'black', b'and', b'white', b'cap', b'on', b'a',\n",
            "  b'street', b'with', b'a', b'bag', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'on', b'the', b'street', b'.', b'a', b'cellphone', b'.', b'.', b'.',\n",
            "  b'on', b'the', b'street', b'.', b'.', b'.', b'on', b'the', b'left',\n",
            "  b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'man', b'in', b'white', b'trunks', b'stands', b'on', b'calm', b'water',\n",
            "  b'.', b'by', b'a', b'body', b'of', b'water', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'watch', b'.', b'.', b'buckets', b'.']]>\n",
            "<tf.RaggedTensor [[b'baseball', b'baseball', b'player', b'in', b'white', b'uniform',\n",
            "  b'swinging', b'at', b'a', b'baseball', b'ball', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'people', b'walking', b'down', b'the', b'street', b'.', b'One', b'the',\n",
            "  b'street', b'.', b'of', b'the', b'road', b'.', b'.', b'on', b'the',\n",
            "  b'street', b'.', b'.', b'on', b'the', b'street', b'.', b'of', b'the',\n",
            "  b'road', b'.', b'.', b'on', b'the', b'road', b'.', b'.', b'.', b'on',\n",
            "  b'the', b'right', b'.']]>\n",
            "<tf.RaggedTensor [[b'wet', b'dog', b'running', b'on', b'the', b'beach', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'on',\n",
            "  b'the', b'beach', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'on',\n",
            "  b'the', b'beach', b'.', b'from', b'the', b'beach', b'.']]>\n",
            "<tf.RaggedTensor [[b'people', b'are', b'walking', b'along', b'a', b'city', b'street', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'watch', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'men', b'in', b'red', b'and', b'white', b'uniforms', b'on', b'a',\n",
            "  b'track', b'.', b'.', b'a', b'track', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'dogs', b'playing', b'with', b'a', b'red', b'ball', b'.', b'a',\n",
            "  b'grassy', b'area', b'.', b'.', b'a', b'second', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'attempts', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'hair', b'are', b'playing', b'in', b'a', b'fairground', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'from', b'the',\n",
            "  b'frame', b'.', b'.', b'from', b'the', b'frame', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'girls', b'in', b'bathing', b'suits', b'are', b'jumping', b'in', b'a',\n",
            "  b'puddle', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'from', b'the', b'left', b'.']]>\n",
            "<tf.RaggedTensor [[b'white', b'and', b'white', b'dog', b'running', b'on', b'grass', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'watches', b'.', b'.', b'.', b'.', b'.', b'and']]>\n",
            "<tf.RaggedTensor [[b'water', b'in', b'black', b'and', b'white', b'cap', b'on', b'a',\n",
            "  b'surfboard', b'.', b'.', b'water', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'dogs', b'are', b'playing', b'in', b'a', b'shallow', b'water', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'shot', b'.', b'into', b'the', b'water',\n",
            "  b'.', b'.', b'from', b'it', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'dogs', b'run', b'through', b'the', b'water', b'.', b'.', b'the',\n",
            "  b'the', b'right', b'.', b'.', b'from', b'the', b'back', b'.', b'.',\n",
            "  b'from', b'the', b'back', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'back', b'on', b'a', b'bench', b'.', b'a', b'man', b\"'s\", b'back',\n",
            "  b'.', b'from', b'the', b'back', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'poodle', b'playing', b'with', b'a', b'toy', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'enjoys', b'.', b'enjoys', b'.', b'enjoys',\n",
            "  b'.', b'enjoys', b'.', b'enjoys', b'.', b\"'s\", b'back', b'.', b\"'s\",\n",
            "  b'back', b'.', b'.', b'.', b'.', b'.', b\"'s\", b'back', b'.', b'enjoys',\n",
            "  b'toy', b'.']]>\n",
            "<tf.RaggedTensor [[b'women', b'in', b'black', b'and', b'white', b'skirts', b'in', b'a',\n",
            "  b'hallway', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'looks', b'.', b'.',\n",
            "  b'in', b'the', b'skirts', b'.', b'in', b'a', b'crowd', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'read', b'seated', b'at', b'a', b'table', b'with', b'a', b'candle',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'covers', b'.', b'toward', b'bookstore', b'.', b'.', b'at']]>\n",
            "<tf.RaggedTensor [[b'boy', b'in', b'a', b'field', b'.', b'.', b'from', b'the', b'ground',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'by', b'others', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'people', b'are', b'standing', b'in', b'front', b'of', b'a', b'large',\n",
            "  b'building', b'.', b'a', b'large', b'blue', b'car', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'touch', b'with', b'baseball', b'hair', b'and', b'blue', b'shirt',\n",
            "  b'holding', b'a', b'red', b'and', b'white', b'cup', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b\"'s\", b'hand', b'.', b'.', b'.', b\"'s\", b'hand', b'.',\n",
            "  b'.']]>\n",
            "<tf.RaggedTensor [[b'dogs', b'play', b'in', b'the', b'water', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'shot',\n",
            "  b'.', b'.', b'shot', b'.', b'.', b'recently', b'.', b'.', b'recently',\n",
            "  b'.', b'.', b'shot', b'.', b'.', b'shot', b'.', b'.', b'recently']]>\n",
            "<tf.RaggedTensor [[b'small', b'child', b'in', b'a', b'pink', b'shirt', b'jumping', b'into',\n",
            "  b'the', b'air', b'.', b'.', b'a', b'small', b'child', b'in', b'a',\n",
            "  b'pink', b'shirt', b'.', b'on', b'the', b'ground', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.']]>\n",
            "<tf.RaggedTensor [[b'wet', b'girl', b'in', b'a', b'swimsuit', b'dumps', b'a', b'sprinkler',\n",
            "  b'.', b'a', b'wet', b'fence', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'african', b'american', b'african', b'a', b'red', b'blanket', b'.',\n",
            "  b'a', b'book', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'people', b'are', b'standing', b'on', b'a', b'boat', b'overlooking',\n",
            "  b'the', b'water', b'.', b'.', b'.', b'out', b'of', b'the', b'water',\n",
            "  b'.', b'from', b'the', b'water', b'.', b'from', b'the', b'water', b'.',\n",
            "  b'from', b'the', b'water', b'.', b'from', b'the', b'water', b'.',\n",
            "  b'from', b'the', b'water', b'.', b'from', b'the']]>\n",
            "<tf.RaggedTensor [[b'skiers', b'skiing', b'down', b'a', b'snowy', b'hill', b'.', b'.',\n",
            "  b'.', b'raised', b'.', b'raised', b'.', b'raised', b'.', b'raised',\n",
            "  b'.', b'raised', b'.', b'raised', b'.', b'raised', b'.', b'raised',\n",
            "  b'.', b'raised', b'.', b'raised', b'.', b'raised', b'.', b'raised',\n",
            "  b'.', b'raised', b'.', b'raised', b'.', b'raised', b'.']]>\n",
            "<tf.RaggedTensor [[b'sled', b'sled', b'sled', b'sled', b'tracks', b'sled', b'.', b'sled',\n",
            "  b'.', b'.', b'driver', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'behind', b'it', b'.', b'.', b'the', b'the', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'behind', b'it', b'.', b'.', b'the', b'the']]>\n",
            "<tf.RaggedTensor [[b'and', b'smiling', b'and', b'smiling', b'at', b'the', b'camera', b'.',\n",
            "  b'of', b'focus', b'cameraman', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'dog', b'jumps', b'over', b'a', b'hurdle', b'.', b'with', b'a', b'jet',\n",
            "  b'of', b'tennis', b'ball', b'in', b'the', b'background', b'.', b'the',\n",
            "  b'the', b'dog', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'seven', b'man', b'in', b'a', b'black', b'shirt', b'is', b'holding',\n",
            "  b'a', b'white', b'in', b'a', b'large', b'brown', b'strip', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'trick', b'on', b'a', b'bike', b'.', b'into', b'the', b'air', b'.',\n",
            "  b'from', b'the', b'ocean', b'.', b'into', b'the', b'sky', b'.', b'.',\n",
            "  b'from', b'the', b'ocean', b'.', b'.', b'into', b'the', b'water', b'.',\n",
            "  b'.', b'from', b'the', b'dunes', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'boat', b'in', b'a', b'boat', b'.', b'.', b'of', b'a', b'boat', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'from', b'the', b'water', b'.', b'from', b'the',\n",
            "  b'water', b'.', b'.', b'from', b'the', b'safety', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'asian', b'woman', b'in', b'black', b'jacket', b'and', b'white',\n",
            "  b'shirt', b'with', b'other', b'women', b'.', b'on', b'her', b'shoulder',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'in', b'a', b'red', b'shirt', b'and', b'a', b'white', b'tie', b'a',\n",
            "  b'back', b'.', b'.', b'a', b'book', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'leaning', b'on', b'a', b'motorcycle', b'.', b'with', b'a', b'crowd',\n",
            "  b'in', b'the', b'background', b'.', b'the', b'the', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'boy', b'riding', b'on', b'a', b'dirt', b'bike', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'in', b'the', b'air', b'.',\n",
            "  b'.', b'in', b'the', b'air', b'.', b'by', b'man']]>\n",
            "<tf.RaggedTensor [[b'back', b'dog', b'with', b'tongue', b'hanging', b'out', b'of', b'the',\n",
            "  b'water', b'.', b'from', b'the', b'ground', b'.', b'from', b'the',\n",
            "  b'ground', b'.', b'from', b'the', b'ground', b'.', b'from', b'the',\n",
            "  b'ground', b'.', b'from', b'the', b'ground', b'.', b'from', b'the',\n",
            "  b'ground', b'.', b'from', b'the', b'ground', b'.', b'from']]>\n",
            "<tf.RaggedTensor [[b'white', b'dog', b'with', b'red', b'collar', b'is', b'jumping',\n",
            "  b'over', b'a', b'white', b'.', b'.', b'pool', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'cold', b'cold', b'winter', b'coats', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b\"'s\", b'face', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b\"'s\", b'face', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'water', b'with', b'a', b'blue', b'life', b'jacket', b'and', b'blue',\n",
            "  b'water', b'.', b'into', b'the', b'pool', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'young', b'boy', b'jumping', b'into', b'the', b'water', b'.', b'.',\n",
            "  b'on', b'the', b'beach', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'small', b'boy', b'in', b'red', b'and', b'white', b'jumping', b'on',\n",
            "  b'a', b'trampoline', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'on', b'the',\n",
            "  b'.', b'.', b'.', b'on', b'the', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'denim', b'elderly', b'man', b'wearing', b'a', b'denim', b'jacket',\n",
            "  b'opening', b'a', b'cigarette', b'.', b'a', b'man', b'in', b'a',\n",
            "  b'denim', b'jacket', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'brown', b'dog', b'is', b'jumping', b'over', b'a', b'red', b'rope',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'it', b'.', b'.', b'it',\n",
            "  b'.', b'.', b'it', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'babies', b'is', b'a', b'baby', b'with', b'a', b'baby', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'people', b'are', b'sitting', b'on', b'a', b'wooden', b'bench', b'.',\n",
            "  b'a', b'tree', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'slide', b'in', b'a', b'bouncy', b'.', b'a', b'blue', b'slide', b'.',\n",
            "  b'.', b'a', b'book', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'smiling', b'young', b'boy', b'with', b'a', b'blue', b'shirt', b'and',\n",
            "  b'blue', b'shorts', b'is', b'smiling', b'with', b'a', b'young', b'boy',\n",
            "  b'in', b'a', b'blue', b'chair', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.']]>\n",
            "<tf.RaggedTensor [[b'sled', b'in', b'red', b'and', b'white', b'cap', b'on', b'bat', b'bat',\n",
            "  b'.', b'.', b'camera', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'watch', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'food', b'man', b'in', b'a', b'blue', b'shirt', b'and', b'a', b'white',\n",
            "  b'cap', b'is', b'sitting', b'in', b'a', b'chair', b'.', b'of', b'a',\n",
            "  b'restaurant', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'stroller', b'child', b'with', b'a', b'baseball', b'and', b'a',\n",
            "  b'helmet', b'on', b'a', b'swing', b'.', b'a', b'stroller', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'hanging', b'from', b'a', b'jungle', b'gym', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'ready', b'to', b'.', b'.', b'from', b'the', b'playground', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'ready', b'to']]>\n",
            "<tf.RaggedTensor [[b'player', b'in', b'red', b'and', b'white', b'running', b'on', b'the',\n",
            "  b'field', b'.', b'of', b'a', b'player', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'football', b'players', b'are', b'being', b'tackled', b'by', b'a',\n",
            "  b'player', b'of', b'people', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'watch']]>\n",
            "<tf.RaggedTensor [[b'girls', b'in', b'a', b'red', b'jacket', b'is', b'holding', b'a',\n",
            "  b'red', b'toy', b'.', b'a', b'flower', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'in', b'a', b'harness', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'in', b'the', b'background', b'.', b'.', b'in',\n",
            "  b'the', b'background', b'.', b'.', b'in', b'the', b'background']]>\n",
            "<tf.RaggedTensor [[b'see', b'boy', b'see', b'the', b'the', b'left', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'skiers', b'skiing', b'down', b'a', b'snowy', b'hill', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'rock', b'climber', b'scaling', b'a', b'rock', b'face', b'.', b'from',\n",
            "  b'a', b'rock', b'face', b'.', b'.', b'from', b'the', b'top', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'brown', b'dog', b'is', b'running', b'through', b'the', b'grass', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'small', b'child', b'in', b'a', b'blue', b'swimsuit', b'holding', b'a',\n",
            "  b'paddle', b'in', b'a', b'shallow', b'pool', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'band', b'in', b'a', b'band', b'.', b'.', b'a', b'book', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'black', b'and', b'white', b'dog', b'running', b'on', b'grass', b'.',\n",
            "  b'with', b'mouth', b'open', b'.', b'on', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'on', b'grass', b'.', b'.', b'on', b'grass',\n",
            "  b'.', b'.', b'on', b'grass', b'.', b'.', b'on', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'boy', b'boy', b'in', b'front', b'of', b'a', b'brick', b'wall', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'dogs', b'leap', b'over', b'a', b'pole', b'.', b'.', b'.', b'.',\n",
            "  b'from', b'the', b'net', b'.', b'from', b'below', b'mother', b'.',\n",
            "  b'from', b'the', b'mother', b'.', b'from', b'the', b'mother', b'.',\n",
            "  b'from', b'the', b'mother', b'.', b'from', b'the', b'mother', b'.',\n",
            "  b'from', b'the', b'mother', b'.', b'from', b'the']]>\n",
            "<tf.RaggedTensor [[b'seated', b'sitting', b'on', b'a', b'wall', b'with', b'a', b'man',\n",
            "  b'in', b'a', b'white', b'shirt', b'and', b'a', b'white', b'bag', b'.',\n",
            "  b'on', b'the', b'floor', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'black', b'dogs', b'run', b'through', b'the', b'water', b'.', b'.',\n",
            "  b'the', b'water', b'.', b'.', b'.', b'.', b'.', b'.', b'recently', b'.',\n",
            "  b'.', b'.', b'recently', b'.', b'.', b'recently', b'.', b'recently',\n",
            "  b'.', b'.', b'recently', b'.', b'.', b'recently', b'.', b'recently',\n",
            "  b'.', b'recently', b'.', b'recently', b'.']]>\n",
            "<tf.RaggedTensor [[b'people', b'are', b'standing', b'in', b'front', b'of', b'a', b'blue',\n",
            "  b'building', b'.', b'a', b'large', b'group', b'of', b'people', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'horse', b'in', b'a', b'red', b'jacket', b'is', b'carrying', b'a',\n",
            "  b'red', b'rope', b'in', b'his', b'mouth', b'.', b'a', b'brown', b'dog',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'man', b'in', b'black', b'jacket', b'standing', b'on', b'a', b'city',\n",
            "  b'street', b'.', b'of', b'a', b'building', b'.', b'.', b'.', b'\"', b'.',\n",
            "  b'\"', b'.', b'\"', b'.', b'\"', b'.', b'\"', b'.', b'\"', b'.', b'\"', b'.',\n",
            "  b'\"', b'.', b'\"', b'.', b'\"', b'.', b'\"', b'.', b'\"']]>\n",
            "<tf.RaggedTensor [[b'people', b'are', b'standing', b'in', b'a', b'body', b'of', b'water',\n",
            "  b'.', b'the', b'the', b'ground', b'.', b'.', b'from', b'the', b'right',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'dog', b'is', b'jumping', b'over', b'a', b'tree', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'asian', b'asian', b'woman', b'wearing', b'black', b'and', b'white',\n",
            "  b'sweater', b'with', b'her', b'head', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b\"'s\",\n",
            "  b\"'s\", b\"'s\", b\"'s\", b\"'s\", b\"'s\", b'head', b'.', b'.', b'.', b'.',\n",
            "  b\"'s\"]]>\n",
            "<tf.RaggedTensor [[b'soccer', b'player', b'in', b'blue', b'and', b'white', b'uniform',\n",
            "  b'playing', b'soccer', b'.', b'on', b'the', b'field', b'.', b'.', b'.',\n",
            "  b'.', b'on', b'the', b'ground', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'on', b'the',\n",
            "  b'field', b'.']]>\n",
            "<tf.RaggedTensor [[b'brown', b'dog', b'is', b'running', b'through', b'a', b'field', b'.',\n",
            "  b'with', b'a', b'rope', b'in', b'its', b'mouth', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'small', b'boy', b'in', b'blue', b'jeans', b'and', b'blue', b'jeans',\n",
            "  b'playing', b'with', b'a', b'toy', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'gather', b'of', b'people', b'sitting', b'on', b'a', b'sidewalk',\n",
            "  b'near', b'a', b'tent', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'watch', b'.', b'.', b'.', b'.', b'.', b'watch', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'BMX', b'bike', b'rider', b'on', b'a', b'beach', b'.', b'on', b'the',\n",
            "  b'beach', b'.', b'to', b'the', b'water', b'.', b'on', b'the', b'beach',\n",
            "  b'.', b'on', b'the', b'beach', b'.', b'to', b'the', b'water', b'.',\n",
            "  b'on', b'the', b'beach', b'.', b'on', b'the', b'beach', b'.', b'on',\n",
            "  b'the', b'beach', b'.']]>\n",
            "<tf.RaggedTensor [[b'wet', b'boy', b'plays', b'in', b'the', b'sprinklers', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'in', b'the',\n",
            "  b'background', b'.', b'.', b'in', b'background', b'.', b'.', b'in',\n",
            "  b'background']]>\n",
            "<tf.RaggedTensor [[b'ice', b'in', b'a', b'red', b'sled', b'slides', b'down', b'a',\n",
            "  b'snowy', b'hill', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'women', b'in', b'black', b'clothes', b'are', b'sitting', b'on', b'a',\n",
            "  b'trampoline', b'.', b'a', b'wooden', b'fence', b'.', b'.', b'a',\n",
            "  b'book', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'dogs', b'are', b'running', b'through', b'a', b'field', b'.', b'with',\n",
            "  b'a', b'stick', b'in', b'its', b'mouth', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'black', b'dogs', b'are', b'running', b'in', b'the', b'grass', b'.',\n",
            "  b'.', b'the', b'the', b'.', b'.', b'.', b'.', b'in', b'the', b'grass',\n",
            "  b'.', b'.', b'the', b'the', b'dog', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'women', b'are', b'sitting', b'on', b'a', b'sidewalk', b'in', b'front',\n",
            "  b'of', b'a', b'store', b'.', b'.', b'.', b'.', b'\"', b'\"', b'\"', b'\"',\n",
            "  b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"',\n",
            "  b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"']]>\n",
            "<tf.RaggedTensor [[b'girl', b'in', b'a', b'red', b'shirt', b'is', b'jumping', b'from',\n",
            "  b'a', b'swing', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'puppy', b'dog', b'with', b'red', b'collar', b'nose', b'nose', b'.',\n",
            "  b'.', b'on', b'nose', b'.', b'.', b'water', b'.', b'.', b'on',\n",
            "  b'camera', b'.', b'.', b'water', b'.', b'.', b'on', b'grass', b'.',\n",
            "  b'water', b'.', b'.', b'on', b'grass', b'.', b'water', b'.', b'.',\n",
            "  b'on', b'grass', b'.', b'water']]>\n",
            "<tf.RaggedTensor [[b'little', b'boy', b'with', b'a', b'brightly', b'colored', b'shirt',\n",
            "  b'is', b'playing', b'with', b'a', b'red', b'swing', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'doing', b'tricks', b'on', b'a', b'skateboard', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'in', b'the',\n",
            "  b'air', b'.', b'.', b'in', b'background', b'.', b'on', b'background',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'basketball', b'player', b'in', b'a', b'blue', b'shirt', b'dribbles',\n",
            "  b'a', b'basketball', b'.', b'.', b'a', b'man', b'.', b'on', b'the',\n",
            "  b'net', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'people', b'sitting', b'on', b'a', b'sidewalk', b'with', b'a',\n",
            "  b'building', b'in', b'front', b'of', b'a', b'brick', b'wall', b'.',\n",
            "  b'a', b'cigarette', b'.', b'.', b'.', b'on', b'the', b'wall', b'.',\n",
            "  b'.', b'.', b'.', b'on', b'the', b'wall', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'people', b'walking', b'down', b'the', b'street', b'.', b'of', b'a',\n",
            "  b'building', b'.', b'a', b'book', b'.', b'.', b'on', b'it', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'man', b'in', b'red', b'jacket', b'pushing', b'a', b'man', b'in', b'a',\n",
            "  b'wheelchair', b'.', b'.', b'a', b'street', b'.', b'a', b'man', b'in',\n",
            "  b'a', b'red', b'jacket', b'.', b'on', b'a', b'city', b'street', b'.',\n",
            "  b'.', b'a', b'street', b'.', b'.', b'.', b'on', b'it', b'.', b'.', b'.',\n",
            "  b'.']]>\n",
            "<tf.RaggedTensor [[b'people', b'are', b'standing', b'on', b'a', b'rock', b'overlooking',\n",
            "  b'the', b'beach', b'.', b'.', b'out', b'of', b'the', b'water', b'.',\n",
            "  b'.', b'.', b'out', b'of', b'the', b'mountains', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'on', b'the', b'beach', b'.', b'.', b'.',\n",
            "  b'out', b'of', b'the']]>\n",
            "<tf.RaggedTensor [[b'blond', b'girl', b'in', b'a', b'pink', b'dress', b'is', b'sitting',\n",
            "  b'on', b'a', b'red', b'bench', b'.', b'.', b'a', b'book', b'.', b'.',\n",
            "  b'her', b'head', b'.', b'her', b'head', b'.', b'her', b'head', b'.',\n",
            "  b'her', b'head', b'.', b'her', b'head', b'.', b'her', b'head', b'.',\n",
            "  b'her', b'head', b'.']]>\n",
            "<tf.RaggedTensor [[b'woman', b'wearing', b'a', b'black', b'jacket', b'and', b'black',\n",
            "  b'cap', b'is', b'posing', b'for', b'a', b'picture', b'.', b'.', b'.',\n",
            "  b'.', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"',\n",
            "  b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"']]>\n",
            "<tf.RaggedTensor [[b'people', b'are', b'walking', b'along', b'a', b'street', b'with', b'a',\n",
            "  b'huge', b'advertisement', b'.', b'.', b'the', b'the', b'right', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'in', b'black', b'and', b'white', b'uniforms', b'jumping', b'in',\n",
            "  b'the', b'air', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'on', b'the', b'right', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'on', b'right', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'girls', b'in', b'black', b'and', b'white', b'uniforms', b'are',\n",
            "  b'standing', b'on', b'a', b'bench', b'.', b'a', b'wall', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'dog', b'stands', b'in', b'water', b'with', b'a', b'stick', b'in',\n",
            "  b'his', b'mouth', b'.', b'and', b'mountains', b'.', b'from', b'the',\n",
            "  b'ground', b'.', b'.', b'from', b'the', b'dock', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b\"'s\", b\"'s\", b\"'s\", b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'people', b'are', b'gathered', b'in', b'a', b'line', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'watch',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'watch', b'.']]>\n",
            "<tf.RaggedTensor [[b'children', b'are', b'playing', b'soccer', b'on', b'a', b'school',\n",
            "  b'floor', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'african', b'black', b'shorts', b'walking', b'along', b'the', b'beach',\n",
            "  b'.', b'into', b'the', b'water', b'.', b'.', b'from', b'the', b'water',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'soccer', b'soccer', b'players', b'kick', b'a', b'soccer', b'ball',\n",
            "  b'.', b'the', b'the', b'.', b'.', b'.', b'.', b'.', b'on', b'the',\n",
            "  b'ground', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'motorcyclist', b'on', b'a', b'motorcycle', b'.', b'with', b'his',\n",
            "  b'motorcycle', b'leaning', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'hoops', b'is', b'a', b'small', b'child', b'in', b'a', b'white',\n",
            "  b'shirt', b'and', b'black', b'pants', b'is', b'jumping', b'over', b'a',\n",
            "  b'pole', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'boat', b'on', b'a', b'boat', b'.', b'by', b'the', b'water', b'.',\n",
            "  b'.', b'from', b'the', b'water', b'.', b'.', b'from', b'the', b'water',\n",
            "  b'.', b'.', b'from', b'the', b'water', b'.', b'.', b'from', b'the',\n",
            "  b'water', b'.', b'.', b'from', b'the', b'water', b'.', b'.', b'from',\n",
            "  b'the', b'water', b'.']]>\n",
            "<tf.RaggedTensor [[b'legs', b'in', b'green', b'shirt', b'and', b'black', b'pants',\n",
            "  b'jumping', b'on', b'concrete', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'girl', b'in', b'a', b'bathing', b'suit', b'is', b'walking', b'along',\n",
            "  b'a', b'sidewalk', b'.', b'by', b'a', b'lake', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'man', b'in', b'camouflage', b'coat', b'and', b'coat', b'standing',\n",
            "  b'on', b'a', b'rock', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'people', b'are', b'riding', b'a', b'red', b'motorcycle', b'.', b'a',\n",
            "  b'heavily', b'path', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'palm', b'american', b'with', b'a', b'blue', b'sky', b'.', b'a',\n",
            "  b'blue', b'sky', b'.', b'.', b'the', b'left', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'dog', b'with', b'brown', b'fur', b'licks', b'nose', b'.', b'with',\n",
            "  b'water', b'.', b'his', b'nose', b'.', b'water', b'.', b'.', b'.',\n",
            "  b'his', b'nose', b'.', b'his', b'mouth', b'.', b'his', b'mouth', b'.',\n",
            "  b'out', b'of', b'frame', b'.', b'.', b'.', b'water', b'.', b'.', b'his',\n",
            "  b'nose', b'.', b'water']]>\n",
            "<tf.RaggedTensor [[b'black', b'and', b'white', b'dog', b'jumping', b'in', b'the', b'air',\n",
            "  b'to', b'catch', b'a', b'Frisbee', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'on',\n",
            "  b'the', b'ground', b'.', b'away', b'.', b'catch', b'.', b'flying', b'.',\n",
            "  b'flying']]>\n",
            "<tf.RaggedTensor [[b'boy', b'boy', b'on', b'a', b'bench', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'heavily', b'.',\n",
            "  b'heavily', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'women', b'walk', b'down', b'a', b'street', b'.', b'a', b'building',\n",
            "  b'.', b'.', b'a', b'book', b'.', b'.', b'.', b'on', b'the', b'sidewalk',\n",
            "  b'.', b'the', b'the', b'right', b'.', b'.', b'.', b'on', b'the',\n",
            "  b'sidewalk', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.']]>\n",
            "<tf.RaggedTensor [[b'sit', b'on', b'a', b'skateboard', b'.', b'over', b'a', b'fence', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'from',\n",
            "  b'the', b'tube', b'.', b'from', b'the', b'tube', b'.']]>\n",
            "<tf.RaggedTensor [[b'man', b'in', b'jeans', b'begging', b'on', b'a', b'street', b'.',\n",
            "  b'with', b'a', b'man', b'in', b'a', b'red', b'jacket', b'.', b'a',\n",
            "  b'book', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'rock', b'climber', b'scaling', b'a', b'rock', b'face', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'on', b'the', b'rock', b'.']]>\n",
            "<tf.RaggedTensor [[b'young', b'girls', b'are', b'playing', b'with', b'a', b'colorful',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'dogs', b'are', b'playing', b'with', b'a', b'ball', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'like', b'a', b'small', b'.', b'.', b'like', b'it', b'.',\n",
            "  b'like', b'it', b'.', b'on', b'the', b'ends', b'.', b'.', b'.', b'like',\n",
            "  b'it', b'.', b'his', b'tongue', b'out', b'.', b'like', b'it', b'.',\n",
            "  b'like']]>\n",
            "<tf.RaggedTensor [[b'mountain', b'biker', b'on', b'bike', b'in', b'forest', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'rural', b'.',\n",
            "  b'marked', b'.', b'.', b'rural', b'.', b'wooded', b'.', b'.', b'wooded',\n",
            "  b'area', b'.', b'.', b'.', b'wooded', b'area', b'.', b'.', b'.',\n",
            "  b'wooded', b'area']]>\n",
            "<tf.RaggedTensor [[b'city', b'driving', b'a', b'truck', b'.', b'a', b'tree', b'.', b'.',\n",
            "  b'it', b'.', b'it', b'.', b'it', b'.', b'it', b'.', b'it', b'.', b'it',\n",
            "  b'.', b'it', b'.', b'it', b'.', b'it', b'.', b'it', b'.', b'it', b'.',\n",
            "  b'it', b'.', b'.', b'it', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'skiers', b'in', b'red', b'jacket', b'to', b'on', b'slope', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'sharp', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'on', b'the', b'sled', b'.', b'.', b'.', b'.', b'on', b'.',\n",
            "  b'sled', b'.', b'.', b'sharp', b'sharp', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'dogs', b'are', b'playing', b'in', b'a', b'body', b'of', b'water',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'like', b'a', b'large', b'waterfall',\n",
            "  b'.', b'.', b'like', b'the', b'water', b'.', b'from', b'the', b'water',\n",
            "  b'.', b'from', b'the', b'water', b'.', b'from', b'the', b'water', b'.',\n",
            "  b'from', b'the', b'water', b'.']]>\n",
            "<tf.RaggedTensor [[b'brown', b'dog', b'is', b'running', b'through', b'a', b'grassy',\n",
            "  b'field', b'.', b'a', b'second', b'dog', b'follows', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'skateboarder', b'in', b'midair', b'performing', b'a', b'trick', b'on',\n",
            "  b'a', b'railing', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'on', b'wall', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'water', b'with', b'a', b'blue', b'life', b'jacket', b'is',\n",
            "  b'swimming', b'in', b'a', b'pool', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'boy', b'boy', b'in', b'a', b'parking', b'lot', b'.', b'a', b'boy',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'park', b'is', b'a', b'large', b'water', b'of', b'water', b'.',\n",
            "  b'from', b'the', b'water', b'.', b'.', b'from', b'the', b'left', b'.',\n",
            "  b'.', b'from', b'the', b'water', b'.', b'from', b'the', b'water', b'.',\n",
            "  b'from', b'the', b'water', b'.', b'from', b'the', b'water', b'.',\n",
            "  b'from', b'the', b'water', b'.', b'from']]>\n",
            "<tf.RaggedTensor [[b'boy', b'in', b'red', b'shirt', b'and', b'blue', b'jeans', b'doing',\n",
            "  b'tricks', b'jump', b'into', b'the', b'air', b'.', b'from', b'the',\n",
            "  b'swing', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'little', b'boy', b'in', b'red', b'shirt', b'plays', b'baseball',\n",
            "  b'baseball', b'baseball', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'watch', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'swimmers', b'in', b'a', b'wetsuit', b'.', b'.', b'the', b'the',\n",
            "  b'ground', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'people', b'are', b'standing', b'on', b'a', b'ledge', b'overlooking',\n",
            "  b'the', b'ocean', b'.', b'.', b'.', b'from', b'the', b'water', b'.',\n",
            "  b'.', b'from', b'the', b'water', b'.', b'.', b'from', b'the', b'water',\n",
            "  b'.', b'from', b'the', b'water', b'.', b'from', b'the', b'water', b'.',\n",
            "  b'from', b'the', b'mountains', b'.', b'from']]>\n",
            "<tf.RaggedTensor [[b'man', b'wearing', b'sunglasses', b'and', b'sunglasses', b'with',\n",
            "  b'sunglasses', b'and', b'blue', b'cap', b'and', b'sunglasses', b'.',\n",
            "  b'on', b'face', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'\"',\n",
            "  b'.', b'\"', b'.', b'\"', b'.', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"', b'\"',\n",
            "  b'\"', b'\"', b'\"']]>\n",
            "<tf.RaggedTensor [[b'black', b'dog', b'jumping', b'in', b'the', b'air', b'to', b'catch',\n",
            "  b'a', b'tennis', b'ball', b'.', b'a', b'tree', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'it', b'.', b'it', b'.', b'it', b'.', b'to', b'it', b'.',\n",
            "  b'.', b'it', b'.', b'it', b'.', b'into', b'the', b'air', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'food', b'in', b'a', b'red', b'outfit', b'is', b'sitting', b'on', b'a',\n",
            "  b'red', b'and', b'blue', b'blanket', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'dogs', b'are', b'running', b'through', b'a', b'field', b'.', b'.',\n",
            "  b'a', b'white', b'dog', b'jumps', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'people', b'are', b'standing', b'in', b'front', b'of', b'a', b'store',\n",
            "  b'.', b'a', b'store', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'skater', b'skateboarder', b'tricks', b'on', b'a', b'railing', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'dogs', b'are', b'playing', b'with', b'a', b'red', b'Frisbee', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'in', b'the', b'background', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'dog', b'is', b'jumping', b'over', b'a', b'large', b'branch', b'.',\n",
            "  b'.', b'.', b'.', b'out', b'of', b'frame', b'.', b'.', b'.', b'.',\n",
            "  b'out', b'of', b'frame', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'players', b'play', b'soccer', b'.', b'.', b'the', b'ball', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'on',\n",
            "  b'the', b'field', b'.', b'.', b'on', b'field', b'.', b'.', b'in',\n",
            "  b'stadium', b'.', b'on', b'field', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'black', b'dogs', b'are', b'playing', b'in', b'the', b'water', b'.',\n",
            "  b'.', b'a', b'tree', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b\"'s\",\n",
            "  b\"'s\", b\"'s\", b'mouths', b'.', b'.', b'out', b'of', b'the', b'water']]>\n",
            "<tf.RaggedTensor [[b'retriever', b'in', b'a', b'field', b'.', b'a', b'second', b'dog',\n",
            "  b'.', b'on', b'the', b'beach', b'.', b'of', b'a', b'second', b'dog',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'in', b'black', b'and', b'white', b'shirt', b'doing', b'a', b'trick',\n",
            "  b'on', b'a', b'skateboard', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'on', b'the', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'the', b'in', b'the', b'ocean', b'.', b'out', b'of', b'the', b'ocean',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'on']]>\n",
            "<tf.RaggedTensor [[b'food', b'man', b'in', b'a', b'blue', b'shirt', b'is', b'sitting',\n",
            "  b'on', b'a', b'bench', b'with', b'a', b'small', b'white', b'.', b'in',\n",
            "  b'a', b'blue', b'shirt', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'young', b'boy', b'in', b'a', b'red', b'jacket', b'playing', b'with',\n",
            "  b'a', b'red', b'sled', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'beach', b'in', b'bathing', b'suits', b'running', b'on', b'beach',\n",
            "  b'.', b'.', b'the', b'beach', b'.', b'.', b'.', b'.', b'.', b'on',\n",
            "  b'the', b'beach', b'.', b'.', b'.', b'on', b'the', b'beach', b'.', b'.',\n",
            "  b'.', b'on', b'the', b'beach', b'.', b'.', b'on', b'the', b'beach',\n",
            "  b'.', b'.', b'on']]>\n",
            "<tf.RaggedTensor [[b'pushing', b'a', b'young', b'girl', b'riding', b'a', b'toy', b'.',\n",
            "  b'down', b'a', b'street', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'people', b'are', b'standing', b'on', b'a', b'mountain', b'.', b'with',\n",
            "  b'a', b'mountain', b'.', b'in', b'the', b'background', b'.', b'the',\n",
            "  b'the', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'grey', b'of', b'water', b'with', b'ducks', b'hair', b'in', b'the',\n",
            "  b'background', b'.', b'from', b'the', b'water', b'.', b'from', b'the',\n",
            "  b'water', b'.', b'from', b'the', b'water', b'.', b'from', b'the',\n",
            "  b'body', b'of', b'water', b'.', b'from', b'the', b'water', b'.',\n",
            "  b'from', b'the', b'body', b'of', b'water', b'.', b'from']]>\n",
            "<tf.RaggedTensor [[b'people', b'walking', b'in', b'a', b'field', b'.', b'a', b'lake', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'white', b'white', b'swimming', b'in', b'the', b'water', b'.', b'from',\n",
            "  b'the', b'water', b'.', b'.', b'from', b'the', b'water', b'.', b'.',\n",
            "  b'from', b'the', b'water', b'.', b'from', b'the', b'water', b'.',\n",
            "  b'from', b'the', b'water', b'.', b'from', b'the', b'water', b'.',\n",
            "  b'from', b'the', b'water', b'.', b'from', b'the']]>\n",
            "<tf.RaggedTensor [[b'wheel', b'wheel', b'car', b'driver', b'.', b'.', b'the', b'the',\n",
            "  b'car', b'.', b'.', b'the', b'driver', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'driver', b'.', b'.', b'.',\n",
            "  b'.', b'driver', b'.', b'.', b'.', b'.', b'driver', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'dogs', b'are', b'running', b'through', b'a', b'grassy', b'area', b'.',\n",
            "  b'a', b'large', b'stick', b'.', b'in', b'the', b'background', b'.',\n",
            "  b'the', b'the', b'.', b'.', b'.', b'.', b'up', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'walking', b'across', b'the', b'water', b'.', b'.', b'recently', b'.',\n",
            "  b'recently', b'.', b'recently', b'.', b'recently', b'.', b'recently',\n",
            "  b'.', b'recently', b'.', b'recently', b'.', b'recently', b'.',\n",
            "  b'recently', b'.', b'recently', b'.', b'recently', b'.', b'recently',\n",
            "  b'.', b'recently', b'.', b'recently', b'.', b'recently', b'.',\n",
            "  b'recently', b'.', b'recently']]>\n",
            "<tf.RaggedTensor [[b'sit', b'in', b'black', b'clothes', b'jackets', b'on', b'a', b'city',\n",
            "  b'street', b'.', b'of', b'a', b'crowd', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'bike', b'rider', b'performing', b'a', b'trick', b'on', b'a', b'bike',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'in', b'the', b'air', b'.']]>\n",
            "<tf.RaggedTensor [[b'jump', b'and', b'a', b'horse', b'jump', b'over', b'a', b'fence', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'watch', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'watch', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'wave', b'with', b'black', b'hair', b'and', b'brown', b'hair', b'and',\n",
            "  b'a', b'wave', b'.', b'wave', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b\"'s\", b'face', b'.', b\"'s\", b'face', b'.',\n",
            "  b'.', b'.', b\"'s\", b'face', b'.', b'.', b'.', b'woman', b\"'s\", b'face']]>\n",
            "<tf.RaggedTensor [[b'woman', b'sitting', b'on', b'floor', b'floor', b'with', b'a',\n",
            "  b'woman', b'in', b'a', b'blue', b'shirt', b'.', b'on', b'a', b'tripod',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'students', b'watch', b'a', b'band', b'.', b'at', b'a', b'man', b'in',\n",
            "  b'a', b'black', b'jacket', b'.', b'a', b'book', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'man', b'in', b'red', b'shirt', b'pushing', b'a', b'pole', b'on', b'a',\n",
            "  b'sidewalk', b'.', b'.', b'a', b'street', b'.', b'.', b'.', b'on',\n",
            "  b'the', b'sidewalk', b'.', b'.', b'.', b'.', b'.', b'the', b'the', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'smiling', b'little', b'girl', b'in', b'a', b'white', b'shirt', b'is',\n",
            "  b'holding', b'a', b'red', b'and', b'red', b'striped', b'shirt', b'.',\n",
            "  b'her', b'eyes', b'closed', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.']]>\n",
            "<tf.RaggedTensor [[b'soccer', b'player', b'in', b'blue', b'shorts', b'running', b'on',\n",
            "  b'a', b'field', b'.', b'a', b'man', b'in', b'a', b'blue', b'shirt',\n",
            "  b'.', b'on', b'the', b'ground', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.']]>\n",
            "<tf.RaggedTensor [[b'trick', b'in', b'midair', b'attempting', b'over', b'a', b'rope', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'in', b'rural', b'.', b'on', b'forest']]>\n",
            "<tf.RaggedTensor [[b'boy', b'boy', b'in', b'front', b'of', b'a', b'brick', b'wall', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'bike', b'rider', b'in', b'the', b'desert', b'.', b'.', b'up', b'the',\n",
            "  b'countryside', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'tricks', b'in', b'orange', b'jacket', b'snowboarding', b'on', b'a',\n",
            "  b'snowy', b'mountain', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'on', b'a', b'snowy', b'mountain', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'structure', b'sitting', b'on', b'a', b'rock', b'.', b'over', b'a',\n",
            "  b'dock', b'.', b'.', b'.', b'from', b'the', b'water', b'.', b'from',\n",
            "  b'the', b'water', b'.', b'from', b'the', b'water', b'.', b'from',\n",
            "  b'the', b'water', b'.', b'from', b'the', b'water', b'.', b'from',\n",
            "  b'the', b'right', b'.', b'out', b'of', b'the']]>\n",
            "<tf.RaggedTensor [[b'brown', b'dog', b'is', b'splashing', b'into', b'the', b'water', b'.',\n",
            "  b'from', b'a', b'body', b'of', b'water', b'.', b'.', b'it', b'.', b'.',\n",
            "  b'it', b'.', b'into', b'the', b'water', b'.', b'.', b'it', b'.', b'it',\n",
            "  b'.', b'it', b'.', b'it', b'.', b'it', b'.', b'it', b'.', b'into',\n",
            "  b'the']]>\n",
            "<tf.RaggedTensor [[b'African', b'and', b'white', b'are', b'standing', b'in', b'front',\n",
            "  b'of', b'a', b'white', b'building', b'.', b'a', b'white', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'boy', b'boy', b'with', b'a', b'toy', b'.', b'.', b'a', b'blue',\n",
            "  b'sky', b'.', b'a', b'blue', b'sky', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'surfer', b'is', b'scaling', b'a', b'huge', b'wave', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'hanging', b'in', b'a', b'backyard', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'from', b'the', b'playground', b'.',\n",
            "  b'.', b'from', b'below', b'.', b'.', b'.', b'.', b'from', b'the',\n",
            "  b'playground', b'.', b'.', b'from', b'below', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'players', b'in', b'red', b'and', b'white', b'uniforms', b'are',\n",
            "  b'stretching', b'a', b'player', b'in', b'a', b'blue', b'uniform', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'watch', b'.', b'.', b'.', b'.',\n",
            "  b'.']]>\n",
            "<tf.RaggedTensor [[b'native', b'in', b'a', b'red', b'jacket', b'.', b'a', b'red', b'and',\n",
            "  b'yellow', b'umbrella', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'brown', b'and', b'white', b'dog', b'jumping', b'over', b'a', b'white',\n",
            "  b'fence', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'attack', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'retriever', b'is', b'jumping', b'into', b'the', b'air', b'to',\n",
            "  b'catch', b'a', b'Frisbee', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'brown', b'dog', b'is', b'running', b'through', b'the', b'grass', b'.',\n",
            "  b'from', b'the', b'water', b'.', b'from', b'the', b'ground', b'.',\n",
            "  b'from', b'the', b'left', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.']]>\n",
            "<tf.RaggedTensor [[b'boy', b'boy', b'sliding', b'down', b'slide', b'.', b'.', b'a',\n",
            "  b'slide', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'people', b'are', b'standing', b'in', b'front', b'of', b'a', b'store',\n",
            "  b'selling', b'with', b'a', b'lit', b'in', b'the', b'background', b'.',\n",
            "  b'the', b'the', b'carnival', b'.', b'.', b'.', b'out', b'of', b'the',\n",
            "  b'carnival', b'.', b'.', b'.', b'.', b'\"', b'.', b'\"', b'.', b'\"', b'.',\n",
            "  b'\"', b'.', b'\"']]>\n",
            "<tf.RaggedTensor [[b'reading', b'in', b'red', b'shirt', b'sitting', b'on', b'a', b'bench',\n",
            "  b'.', b'a', b'book', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'people', b'are', b'sitting', b'in', b'a', b'crowded', b'street', b'.',\n",
            "  b'.', b'a', b'book', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'man', b'in', b'white', b'shirt', b'and', b'white', b'cap', b'on',\n",
            "  b'a', b'skateboard', b'.', b'a', b'cigarette', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'people', b'are', b'walking', b'through', b'a', b'mountain', b'.',\n",
            "  b'.', b'.', b'.', b'and', b'looks', b'on', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'boy', b'in', b'blue', b'shirt', b'and', b'blue', b'jeans', b'is',\n",
            "  b'playing', b'with', b'a', b'red', b'pole', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'small', b'puppies', b'dog', b'kissing', b'in', b'the', b'air', b'.',\n",
            "  b'from', b'a', b'pool', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'it', b'.', b'from']]>\n",
            "<tf.RaggedTensor [[b'cyclist', b'is', b'riding', b'a', b'bike', b'on', b'a', b'dirt',\n",
            "  b'track', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'small', b'dogs', b'playing', b'with', b'a', b'tennis', b'ball', b'in',\n",
            "  b'a', b'grassy', b'field', b'.', b'.', b'a', b'second', b'and', b'a',\n",
            "  b'white', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'boy', b'boy', b'in', b'water', b'.', b'on', b'a', b'blue', b'slide',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'white', b'dog', b'with', b'white', b'collar', b'is', b'walking',\n",
            "  b'through', b'water', b'.', b'with', b'water', b'.', b'in', b'the',\n",
            "  b'background', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'in',\n",
            "  b'water', b'.', b'.', b'in', b'the', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'behind', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'sunset', b'with', b'flag', b'flag', b',', b'and', b'flag', b'man',\n",
            "  b'in', b'background', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'kids', b'are', b'standing', b'around', b'a', b'fence', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'watch', b'.', b'.', b'.', b'.', b'by']]>\n",
            "<tf.RaggedTensor [[b'man', b'in', b'black', b'and', b'white', b'cap', b'on', b'a',\n",
            "  b'street', b'bench', b'.', b'a', b'road', b'.', b'.', b'.', b'.', b'on',\n",
            "  b'the', b'street', b'.', b'.', b'.', b'on', b'the', b'street', b'.',\n",
            "  b'of', b'a', b'road', b'.', b'.', b'.', b'on', b'the', b'street', b'.',\n",
            "  b'the', b'the']]>\n",
            "<tf.RaggedTensor [[b'dog', b'is', b'running', b'through', b'a', b'field', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'girl', b'in', b'red', b'shirt', b'and', b'white', b'sneakers',\n",
            "  b'shirt', b'hangs', b'upside', b'down', b'.', b'.', b'.', b'tree', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'brown', b'dog', b'is', b'jumping', b'up', b'to', b'catch', b'a',\n",
            "  b'Frisbee', b'.', b'from', b'a', b'tree', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'people', b'waiting', b'in', b'the', b'street', b'.', b'of', b'a',\n",
            "  b'car', b'.', b'.', b'.', b'.', b'out', b'of', b'the', b'street', b'.',\n",
            "  b'of', b'a', b'car', b'.', b'.', b'.', b'.', b'.', b'.', b'out', b'of',\n",
            "  b'the', b'road', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'wet', b'dog', b'with', b'pointed', b'in', b'mouth', b'water', b'.',\n",
            "  b'with', b'a', b'stick', b'in', b'his', b'mouth', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b\"'s\", b\"'s\", b\"'s\"]]>\n",
            "<tf.RaggedTensor [[b'little', b'girl', b'in', b'a', b'pink', b'dress', b'is', b'sitting',\n",
            "  b'on', b'a', b'red', b'swing', b'.', b'her', b'palm', b'.', b'her',\n",
            "  b'mouth', b'.', b'.', b'her', b'face', b'.', b'her', b'face', b'.',\n",
            "  b'her', b'face', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'huge', b'in', b'red', b'and', b'white', b'and', b'white', b'biking',\n",
            "  b'in', b'the', b'snow', b'.', b'in', b'the', b'background', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'in', b'the', b'.', b'.', b'.', b'in', b'the', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'floating', b'on', b'a', b'ride', b'.', b'.', b'a', b'lake', b'.',\n",
            "  b'.', b'.', b'.', b'from', b'the', b'water', b'.', b'from', b'the',\n",
            "  b'water', b'.', b'from', b'the', b'water', b'.', b'from', b'the',\n",
            "  b'water', b'.', b'from', b'the', b'slide', b'.', b'.', b'from', b'the',\n",
            "  b'slide', b'.', b'.', b'the']]>\n",
            "<tf.RaggedTensor [[b'brown', b'dog', b'is', b'jumping', b'over', b'a', b'white', b'tree',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'young', b'boy', b'with', b'a', b'red', b'shirt', b'is', b'riding',\n",
            "  b'a', b'red', b'horse', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'boy', b'boy', b'a', b'red', b'toy', b'.', b'a', b'book', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'skateboarder', b'doing', b'tricks', b'stunt', b'.', b'ramp', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'stunt', b'.', b'.', b'.', b'on', b'skateboard', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'stunt', b'.', b'.', b'stunt', b'.', b'.', b'on',\n",
            "  b'skateboard']]>\n",
            "<tf.RaggedTensor [[b'people', b'walking', b'across', b'the', b'beach', b'carrying', b'a',\n",
            "  b'white', b'.', b'.', b'.', b'on', b'the', b'beach', b'.', b'of',\n",
            "  b'the', b'water', b'.', b'.', b'on', b'it', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.']]>\n",
            "<tf.RaggedTensor [[b'black', b'and', b'white', b'dog', b'is', b'running', b'through',\n",
            "  b'the', b'grass', b'.', b'with', b'mouth', b'in', b'mouth',\n",
            "  b'background', b'.', b'.', b'on', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'attempts', b'.', b'.', b'.', b'with', b'a',\n",
            "  b'red', b'and', b'white', b'dog', b'in']]>\n",
            "<tf.RaggedTensor [[b'baby', b'in', b'a', b'blue', b'shirt', b'is', b'holding', b'a',\n",
            "  b'red', b'and', b'white', b'toy', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'are', b'riding', b'a', b'mountain', b'trail', b'of', b'a', b'snowy',\n",
            "  b'mountain', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'mountain', b'biker', b'on', b'a', b'bike', b'.', b'through', b'the',\n",
            "  b'woods', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'heavily', b'.', b'heavily', b'.', b'.', b'.', b'heavily', b'.']]>\n",
            "<tf.RaggedTensor [[b'hanging', b'in', b'a', b'forest', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'from', b'the', b'rope', b'.', b'from',\n",
            "  b'the', b'tree', b'.', b'from', b'the', b'tree', b'.', b'from', b'the',\n",
            "  b'tree', b'limb', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'are', b'riding', b'a', b'large', b'flag', b'.', b'.', b'of', b'a',\n",
            "  b'building', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'wet', b'dog', b'splashing', b'in', b'water', b'.', b'.', b'.', b'.',\n",
            "  b'.', b\"'s\", b'hair', b'.', b'.', b'.', b'.', b'.', b\"'s\", b'hair',\n",
            "  b'.', b'hair', b'.', b'hair', b'hair', b'hair', b'hair', b'hair',\n",
            "  b'hair', b'hair', b'hair', b'hair', b'hair', b'hair', b'hair', b'in',\n",
            "  b'water', b'.', b'from', b'the']]>\n",
            "<tf.RaggedTensor [[b'people', b'walking', b'down', b'the', b'street', b'.', b'a',\n",
            "  b'building', b'.', b'a', b'white', b'.', b'.', b'on', b'it', b'.', b'.',\n",
            "  b'a', b'white', b'.', b'.', b'.', b'on', b'the', b'side', b'.', b'.',\n",
            "  b'.', b'.', b'on', b'the', b'left', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'the']]>\n",
            "<tf.RaggedTensor [[b'women', b'in', b'black', b'and', b'white', b'uniforms', b'are',\n",
            "  b'singing', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'white', b'dog', b'with', b'a', b'red', b'collar', b'running',\n",
            "  b'through', b'the', b'grass', b'.', b'.', b'a', b'white', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'people', b'dressed', b'in', b'cold', b'clothes', b'are', b'standing',\n",
            "  b'in', b'front', b'of', b'a', b'giant', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'man', b'in', b'a', b'red', b'jacket', b'is', b'sitting', b'on', b'a',\n",
            "  b'bench', b'.', b'a', b'cigarette', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'#', b'race', b'race', b'on', b'track', b'.', b'track', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'lead', b'.', b'.', b'the', b'track', b'.', b'.', b'.', b'.', b'lead',\n",
            "  b'.', b'.', b'the', b'track', b'.', b'.', b'track', b'.']]>\n",
            "<tf.RaggedTensor [[b'men', b'in', b'formal', b'attire', b'pose', b'for', b'a', b'picture',\n",
            "  b'.', b'a', b'building', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'sled', b'sled', b'sled', b'sled', b'through', b'the', b'snow', b'.',\n",
            "  b'2', b'sled', b'sets', b'.', b'.', b'behind', b'it', b'.', b'.',\n",
            "  b'the', b'the', b'.', b'.', b'.', b'behind', b'it', b'.', b'.', b'sled',\n",
            "  b'.', b'sled', b'.', b'sled', b'.', b'sled', b'.', b'sled', b'.',\n",
            "  b'sled', b'.', b'sled']]>\n",
            "<tf.RaggedTensor [[b'white', b'white', b'dog', b'swimming', b'in', b'water', b'.', b'from',\n",
            "  b'a', b'body', b'of', b'water', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b\"'s\", b'edge', b'.', b'.', b'.', b\"'s\", b'edge', b'.', b'dog', b\"'s\",\n",
            "  b'back', b'.', b'swimming', b'.', b'.', b\"'s\", b'edge', b'.', b'dog',\n",
            "  b\"'s\", b'back']]>\n",
            "<tf.RaggedTensor [[b'boy', b'boy', b'on', b'a', b'bench', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'watch', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'on', b'right', b'.']]>\n",
            "<tf.RaggedTensor [[b'swings', b'on', b'a', b'rope', b'swing', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'swinging', b'.', b'swinging', b'.', b'from', b'the',\n",
            "  b'swing', b'.', b'.', b'.', b'.', b'.', b'.', b'on']]>\n",
            "<tf.RaggedTensor [[b'bike', b'rider', b'with', b'a', b'bicycle', b'on', b'the', b'street',\n",
            "  b'.', b'the', b'street', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'old', b'boy', b'on', b'a', b'bench', b'.', b'a', b'trail', b'of',\n",
            "  b'water', b'.', b'from', b'the', b'right', b'.', b'.', b'.', b'on',\n",
            "  b'a', b'city', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'boy', b'in', b'a', b'stroller', b'.', b'a', b'stroller', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'reading', b'sitting', b'on', b'a', b'bench', b'reading', b'a',\n",
            "  b'book', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'man', b'riding', b'a', b'bike', b'on', b'a', b'bench', b'.', b'a',\n",
            "  b'man', b'.', b'on', b'a', b'bike', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'no', b'dog', b'jumping', b'over', b'a', b'fence', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'\"', b'.', b'\"', b'.', b'\"', b'.', b'\"', b'.', b'\"',\n",
            "  b'.', b'\"', b'.', b'\"', b'.', b'\"', b'\"', b'\"', b'\"', b'.', b'\"', b'.',\n",
            "  b'\"', b'.', b'\"', b'\"', b'.', b'\"']]>\n",
            "<tf.RaggedTensor [[b'rock', b'climber', b'climbing', b'a', b'rock', b'face', b'.', b'.',\n",
            "  b'wall', b'.', b'.', b'.', b'.', b'.', b'.', b'climb', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'climb', b'.', b'wall', b'.', b'wall', b'.', b'wall']]>\n",
            "<tf.RaggedTensor [[b'young', b'girls', b'are', b'standing', b'in', b'front', b'of', b'a',\n",
            "  b'large', b'tree', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b\"'s\", b'eyes', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'art', b'in', b'blue', b'jeans', b'and', b'white', b'pants', b'on',\n",
            "  b'a', b'tile', b'floor', b'.', b'.', b'from', b'the', b'steps', b'.',\n",
            "  b'from', b'the', b'steps', b'.', b'from', b'the', b'steps', b'.',\n",
            "  b'from', b'the', b'steps', b'.', b'.', b'from', b'the', b'steps', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'in', b'a', b'field', b'.', b'a', b'red', b'rope', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'goalie', b'in', b'a', b'white', b'uniform', b'and', b'a', b'man',\n",
            "  b'in', b'a', b'white', b'shirt', b'are', b'playing', b'basketball',\n",
            "  b'.', b'a', b'crowd', b'.', b'.', b'the', b'the', b'basket', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'teen', b'laughing', b'asian', b'asian', b'girl', b'sitting', b'at',\n",
            "  b'a', b'table', b'with', b'a', b'pacifier', b'in', b'her', b'hand',\n",
            "  b'.', b'.', b'a', b'book', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.']]>\n",
            "<tf.RaggedTensor [[b'dogs', b'are', b'playing', b'in', b'a', b'fenced', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'behind', b'it', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'it', b'.', b'.', b'it', b'.', b'by', b'it', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'it', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'biker', b'on', b'a', b'track', b'.', b'on', b'a', b'track', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'fishing', b'young', b'boys', b'wearing', b'baseball', b't-shirts',\n",
            "  b'and', b'look', b'at', b'a', b'fairground', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'driver', b'.', b'.', b'.', b'.', b'driver', b'.', b'.', b'.',\n",
            "  b'.', b'driver']]>\n",
            "<tf.RaggedTensor [[b'brown', b'and', b'white', b'dog', b'jumping', b'over', b'a',\n",
            "  b'hurdle', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'attack', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'yelling', b'in', b'bathing', b'suits', b'walking', b'on', b'beach',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'people', b'sitting', b'on', b'a', b'bench', b'with', b'a', b'tree',\n",
            "  b'.', b'on', b'the', b'left', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'soccer', b'player', b'in', b'red', b'and', b'white', b'running',\n",
            "  b'on', b'a', b'grassy', b'field', b'.', b'a', b'soccer', b'ball', b'.',\n",
            "  b'the', b'right', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'smiling', b'woman', b'with', b'a', b'red', b'shirt', b'is',\n",
            "  b'smiling', b'with', b'her', b'hand', b'in', b'the', b'foreground',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.']]>\n",
            "<tf.RaggedTensor [[b'black', b'and', b'white', b'dog', b'jumping', b'in', b'the', b'snow',\n",
            "  b'.', b'a', b'black', b'dog', b'in', b'the', b'background', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'looks', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'#', b'#', b'8', b'#', b')', b'on', b'track', b'.', b'track', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'#',\n",
            "  b'.', b'.', b'on', b'the', b'track', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'#', b'.', b'.', b'on', b'track']]>\n",
            "<tf.RaggedTensor [[b'competition', b'are', b'playing', b'with', b'a', b'red', b'toy', b'.',\n",
            "  b'a', b'grassy', b'area', b'.', b'.', b'a', b'blue', b'rope', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'creek', b'in', b'sneakers', b'shorts', b'and', b'sneakers', b'sit',\n",
            "  b'on', b'rocks', b'.', b'of', b'rocks', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'on', b'the', b'water',\n",
            "  b'.', b'.', b'on', b'the', b'rocks', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'jump', b'in', b'a', b'band', b'.', b'.', b'a', b'jump', b'.', b'a',\n",
            "  b'jump', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'dogs', b'run', b'through', b'the', b'woods', b'.', b'.', b'.', b'.',\n",
            "  b'up', b'.', b'way', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'behind', b'.', b'.', b'.', b'.', b'behind', b'.',\n",
            "  b'.', b'.', b'.', b'behind', b'.', b'.', b'.', b'.', b'behind']]>\n",
            "<tf.RaggedTensor [[b'people', b'are', b'in', b'a', b'river', b'.', b'a', b'large',\n",
            "  b'river', b'.', b'.', b'the', b'water', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'woman', b'in', b'black', b'skirt', b'and', b'white', b'skirt', b'on',\n",
            "  b'top', b'of', b'her', b'head', b'in', b'front', b'of', b'her', b'.',\n",
            "  b'.', b'.', b'on', b'the', b'floor', b'.', b'.', b'on', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'on', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'motorcyclist', b'in', b'red', b'and', b'white', b'riding', b'a',\n",
            "  b'bike', b'jump', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'watch', b'.', b'.', b'.', b'.', b'.', b'watch', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'smiling', b'young', b'boy', b'with', b'a', b'blue', b'shirt', b'and',\n",
            "  b'a', b'white', b'shirt', b'and', b'a', b'smile', b'.', b'.', b'.',\n",
            "  b'peace', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'brown', b'dog', b'is', b'walking', b'through', b'the', b'snow', b'.',\n",
            "  b'from', b'the', b'ground', b'.', b'from', b'the', b'edge', b'of',\n",
            "  b'frame', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'swing', b'swing', b'on', b'a', b'swing', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'swings', b'.',\n",
            "  b'from', b'the', b'swing', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'skier', b'is', b'skiing', b'down', b'a', b'snowy', b'hill', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'dog', b'walking', b'through', b'water', b'.', b'with', b'a', b'stick',\n",
            "  b'in', b'his', b'mouth', b'.', b'and', b'a', b'black', b'dog', b'.',\n",
            "  b'on', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'from', b'a']]>\n",
            "<tf.RaggedTensor [[b'denim', b'in', b'blue', b'shirt', b'and', b'jeans', b'sitting', b'on',\n",
            "  b'hardwood', b'floor', b'.', b'a', b'magazine', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'toward', b'balance']]>\n",
            "<tf.RaggedTensor [[b'on', b'a', b'track', b'.', b'on', b'a', b'racetrack', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'on', b'road']]>\n",
            "<tf.RaggedTensor [[b'football', b'football', b'in', b'red', b'and', b'white', b'uniform',\n",
            "  b'jumping', b'in', b'the', b'field', b'.', b'of', b'the', b'field',\n",
            "  b'.', b'from', b'the', b'ground', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'adults', b'are', b'sitting', b'on', b'the', b'street', b'waving',\n",
            "  b'a', b'white', b'pole', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'Indian', b'Indian', b'Indian', b'water', b'.', b'with', b'water',\n",
            "  b'.', b'in', b'the', b'background', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'white', b'and', b'white', b'dog', b'running', b'through', b'the',\n",
            "  b'leafy', b'grass', b'.', b'.', b'.', b'.', b'in', b'background', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'legs', b'in', b'shorts', b'and', b'sneakers', b'running', b'on', b'a',\n",
            "  b'wet', b'track', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'brown', b'and', b'white', b'dog', b'running', b'through', b'snow',\n",
            "  b'.', b'.', b'camera', b'.', b'.', b'in', b'background', b'.', b'.',\n",
            "  b'.', b'in', b'background', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'in']]>\n",
            "<tf.RaggedTensor [[b'track', b'down', b'down', b'track', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'behind', b'it', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'on',\n",
            "  b'the', b'track', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'rock', b'climber', b'scaling', b'a', b'rock', b'face', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'on', b'the']]>\n",
            "<tf.RaggedTensor [[b'against', b'boy', b'in', b'red', b'shirt', b'standing', b'on', b'a',\n",
            "  b'wall', b'.', b'a', b'wall', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'young', b'boy', b'in', b'a', b'blue', b'shirt', b'is', b'walking',\n",
            "  b'along', b'a', b'blue', b'chair', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'people', b'riding', b'horses', b'bikes', b'on', b'a', b'dirt',\n",
            "  b'track', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'watch', b'.', b'.', b'.', b'.', b'watch', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'denim', b'of', b'people', b'are', b'standing', b'in', b'front', b'of',\n",
            "  b'a', b'large', b'blue', b'tube', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'looks', b'.']]>\n",
            "<tf.RaggedTensor [[b'brown', b'dog', b'and', b'a', b'white', b'dog', b'are', b'playing',\n",
            "  b'in', b'the', b'water', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b\"'s\",\n",
            "  b'shoulder', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'man', b'in', b'uniform', b'standing', b'near', b'a', b'crowd', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'boy', b'on', b'a', b'bike', b'.', b'down', b'the', b'road', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'in', b'the']]>\n",
            "<tf.RaggedTensor [[b'5', b'in', b'a', b'race', b'.', b'.', b'from', b'the', b'left', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'dog', b'with', b'a', b'red', b'collar', b'running', b'in', b'the',\n",
            "  b'grass', b'.', b'a', b'wooded', b'area', b'.', b'the', b'ground', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'boys', b'in', b'red', b'shirt', b'jumping', b'off', b'a', b'set',\n",
            "  b'of', b'stairs', b'.', b'.', b'.', b'.', b'on', b'a', b'city',\n",
            "  b'street', b'.', b'.', b'from', b'the', b'ground', b'.', b'from',\n",
            "  b'the', b'ground', b'.', b'from', b'the', b'ground', b'.', b'from',\n",
            "  b'the', b'ground', b'.', b'from', b'the', b'ground']]>\n",
            "<tf.RaggedTensor [[b'in', b'swim', b'trunks', b'leaping', b'on', b'beach', b'.', b'into',\n",
            "  b'the', b'ocean', b'.', b'.', b'on', b'the', b'beach', b'.', b'into',\n",
            "  b'the', b'distance', b'.', b'.', b'on', b'the', b'beach', b'.', b'into',\n",
            "  b'the', b'lake', b'.', b'.', b'on', b'the', b'beach', b'.', b'into',\n",
            "  b'the', b'lake', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'man', b'in', b'white', b'shirt', b'and', b'white', b'cap',\n",
            "  b'standing', b'on', b'a', b'city', b'street', b'.', b'of', b'a',\n",
            "  b'building', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.']]>\n",
            "<tf.RaggedTensor [[b'legs', b'in', b'green', b'pants', b'and', b'blue', b'helmet',\n",
            "  b'jumping', b'on', b'a', b'wet', b'field', b'.', b'.', b'the',\n",
            "  b'ground', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.']]>\n",
            "<tf.RaggedTensor [[b'in', b'a', b'parade', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'in', b'the', b'background']]>\n",
            "<tf.RaggedTensor [[b'hockey', b'player', b'in', b'red', b'and', b'white', b'uniform',\n",
            "  b'on', b'the', b'ice', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'on']]>\n",
            "<tf.RaggedTensor [[b'bald', b'band', b'playing', b'guitars', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'in', b'background', b'.', b'on', b'guitar', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'watch',\n",
            "  b'.', b'.', b'microphone', b'microphone', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.']]>\n",
            "<tf.RaggedTensor [[b'brown', b'dog', b'is', b'biting', b'a', b'large', b'stick', b'in',\n",
            "  b'the', b'face', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'woman', b'wearing', b'a', b'blue', b'shirt', b'sitting', b'on', b'a',\n",
            "  b'chair', b'.', b'.', b'a', b'book', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'on', b'a', b'beach', b'.', b'into', b'the', b'water', b'.', b'from',\n",
            "  b'the', b'water', b'.', b'from', b'the', b'water', b'.', b'from',\n",
            "  b'the', b'water', b'.', b'from', b'the', b'water', b'.', b'from',\n",
            "  b'the', b'water', b'.', b'from', b'the', b'water', b'.', b'from',\n",
            "  b'the', b'water', b'.', b'from', b'the', b'water']]>\n",
            "<tf.RaggedTensor [[b'no', b'boy', b'in', b'blue', b'shirt', b'and', b'blue', b'jeans',\n",
            "  b'and', b'blue', b'jeans', b'and', b'blue', b'shirt', b'are',\n",
            "  b'standing', b'in', b'front', b'of', b'a', b'large', b'tree', b'.',\n",
            "  b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.']]>\n",
            "<tf.RaggedTensor [[b'women', b'in', b'orange', b'shirt', b'riding', b'a', b'blue', b'car',\n",
            "  b'.', b'a', b'brick', b'building', b'.', b'from', b'the', b'camera',\n",
            "  b'.', b'of', b'a', b'brick', b'building', b'.', b'a', b'woman', b'in',\n",
            "  b'a', b'red', b'shirt', b'looks', b'on', b'.', b'.', b'.', b'.', b'.',\n",
            "  b'.', b'.', b'.', b'.']]>\n"
          ]
        }
      ],
      "source": [
        "# rogue and bleu results\n",
        "\n",
        "rogue_scores, bleu_scores, predicted_captions = calculate_metrics('all', current_lstm_model, testImgsPaths, testImgToFeatures, testImgToCaptions, \n",
        "                                                   maxCapLen, lstm_wordToIdx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# checking out the average of all scores:\n",
        "print('average of all rogue scores:')\n",
        "print(round(sum(rogue_scores) / len(rogue_scores), 5))\n",
        "\n",
        "# checking out result of 1st test image:\n",
        "print('1st rogue score:')\n",
        "print(rogue_scores[0])\n",
        "\n",
        "print()\n",
        "\n",
        "# checking out the average of all scores:\n",
        "print('average of all bleu scores:')\n",
        "print(round(sum(bleu_scores) / len(bleu_scores), 5))\n",
        "\n",
        "# checking out result of 1st test image:\n",
        "print('1st bleu score:')\n",
        "print(bleu_scores[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "# checking out a predicted/actual caption along with an image used:\n",
        "\n",
        "print('predicted caption:')\n",
        "print(predicted_captions[0])\n",
        "print('actual captions:')\n",
        "img_id = os.path.splitext(os.path.basename(testImgsPaths[0]))[0] \n",
        "print(testImgToCaptions[img_id])\n",
        "print('the image itself:')\n",
        "x = plt.imread(testImgsPaths[0])\n",
        "plt.imshow(x)\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GRU Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# hyperparameters used when model was trained:\n",
        "droput_rate = 0.5\n",
        "dense_layer_units = 256\n",
        "hidden_layers_activation = 'relu'\n",
        "\n",
        "current_gru_model = create_gru_model(embedding_matrix, vocabSize, droput_rate, dense_layer_units, hidden_layers_activation)\n",
        "current_gru_model.load_weights(f'models/gru_weights/gru_epochs_of-0030-and_val_loss_of-3.5945.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# rogue and bleu results\n",
        "\n",
        "rogue_scores, bleu_scores, predicted_captions = calculate_metrics('all', current_gru_model, testImgsPaths, testImgToFeatures, testImgToCaptions, \n",
        "                                                   maxCapLen, lstm_wordToIdx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# checking out the average of all scores:\n",
        "print('average of all rogue scores:')\n",
        "print(round(sum(rogue_scores) / len(rogue_scores), 5))\n",
        "\n",
        "# checking out result of 1st test image:\n",
        "print('1st rogue score:')\n",
        "print(rogue_scores[0])\n",
        "\n",
        "print()\n",
        "\n",
        "# checking out the average of all scores:\n",
        "print('average of all bleu scores:')\n",
        "print(round(sum(bleu_scores) / len(bleu_scores), 5))\n",
        "\n",
        "# checking out result of 1st test image:\n",
        "print('1st bleu score:')\n",
        "print(bleu_scores[0])\n",
        "# checking out a predicted/actual caption along with an image used:\n",
        "\n",
        "print('predicted caption:')\n",
        "print(predicted_captions[0])\n",
        "print('actual captions:')\n",
        "img_id = os.path.splitext(os.path.basename(testImgsPaths[0]))[0] \n",
        "print(testImgToCaptions[img_id])\n",
        "print('the image itself:')\n",
        "x = plt.imread(testImgsPaths[0])\n",
        "plt.imshow(x)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "c7cdde67bd1df58aee8e05336b4c9e41dfb37650659bf34d4c10242d0898ac5a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
